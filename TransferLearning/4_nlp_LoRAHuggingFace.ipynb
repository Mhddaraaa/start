{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-a-sCLZtJ-Wc"
      },
      "source": [
        "## Resources\n",
        "\n",
        "[GPT illustration](https://jalammar.github.io/illustrated-gpt2/)\n",
        "\n",
        "[Fine tune casual LM and mask LM in colab](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling.ipynb)\n",
        "\n",
        "[Causal language modeling](https://huggingface.co/docs/transformers/tasks/language_modeling)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "uoeFoxewJ4sg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from IPython.display import display, HTML\n",
        "import html\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_UURfQjUnnT"
      },
      "source": [
        "## Work with dataset\n",
        "\n",
        "[Reference](https://huggingface.co/learn/llm-course/chapter5/3)\n",
        "\n",
        "If you've loaded a dataFrame use this method:\n",
        "\n",
        "```py\n",
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "full_dataset = Dataset.from_pandas(df)\n",
        "dataset = full_dataset.train_test_split(test_size=0.2, seed=42)\n",
        "\n",
        "# --------------------------------------------------------------\n",
        "# Or\n",
        "train_size = int(0.8 * len(df))\n",
        "val_size = train_size + int(0.1 * len(df))\n",
        "train_df = df[: train_size]\n",
        "val_df = df[train_size: val_size]\n",
        "test_df = df[val_size:]\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "val_dataset = Dataset.from_pandas(val_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Create DatasetDict\n",
        "dataset = DatasetDict({\n",
        "    \"train\": train_dataset,\n",
        "    \"validation\": valval_dataset_df,\n",
        "    \"test\": test_dataset\n",
        "})\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fT6JvfaUFaAA"
      },
      "outputs": [],
      "source": [
        "!wget \"https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip\"\n",
        "!unzip drugsCom_raw.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "1IOfAW7RTnoG",
        "outputId": "7976054a-f0fc-4a71-e7e3-5eb198fa3606"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>drugName</th>\n",
              "      <th>condition</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "      <th>date</th>\n",
              "      <th>usefulCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>163740</td>\n",
              "      <td>Mirtazapine</td>\n",
              "      <td>Depression</td>\n",
              "      <td>\"I&amp;#039;ve tried a few antidepressants over the years (citalopram, fluoxetine, amitriptyline), but none of those helped with my depression, insomnia &amp;amp; anxiety. My doctor suggested and changed me onto 45mg mirtazapine and this medicine has saved my life. Thankfully I have had no side effects especially the most common - weight gain, I&amp;#039;ve actually lost alot of weight. I still have suicidal thoughts but mirtazapine has saved me.\"</td>\n",
              "      <td>10.0</td>\n",
              "      <td>February 28, 2012</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>206473</td>\n",
              "      <td>Mesalamine</td>\n",
              "      <td>Crohn's Disease, Maintenance</td>\n",
              "      <td>\"My son has Crohn&amp;#039;s disease and has done very well on the Asacol.  He has no complaints and shows no side effects.  He has taken as many as nine tablets per day at one time.  I&amp;#039;ve been very happy with the results, reducing his bouts of diarrhea drastically.\"</td>\n",
              "      <td>8.0</td>\n",
              "      <td>May 17, 2009</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>159672</td>\n",
              "      <td>Bactrim</td>\n",
              "      <td>Urinary Tract Infection</td>\n",
              "      <td>\"Quick reduction of symptoms\"</td>\n",
              "      <td>9.0</td>\n",
              "      <td>September 29, 2017</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drugsComTest_raw.tsv', sep = '\\t') # TSV use tab (\\t)) as seperator\n",
        "display(HTML(df.head(3).to_html()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58JQeBMIadVd"
      },
      "source": [
        "### Feed dataset into dataset_load class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uePp8kLT0WU"
      },
      "outputs": [],
      "source": [
        "# Before feeding data into load_dataset class, we should split it, we can do it later though.\n",
        "data_files = {\"train\": \"/content/drugsComTrain_raw.tsv\", \"test\": \"/content/drugsComTest_raw.tsv\"}\n",
        "dataset = load_dataset(\"csv\", data_files = data_files, delimiter = '\\t')\n",
        "dataset = dataset.rename_column(\"Unnamed: 0\", \"id\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iVMG1NSZb3X",
        "outputId": "bbd7ac7c-7fac-4840-ba08-0637e85690f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],\n",
              "        num_rows: 161297\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],\n",
              "        num_rows: 53766\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pbwj3Jq0VBzP",
        "outputId": "a16de46f-7f67-4579-aed6-f9d19716fd3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': [178045, 80482],\n",
              " 'drugName': ['Duloxetine', 'Mobic'],\n",
              " 'condition': ['ibromyalgia', 'Inflammatory Conditions'],\n",
              " 'review': ['\"I have taken Cymbalta for about a year and a half for fibromyalgia pain. It is great\\r\\nas a pain reducer and an anti-depressant, however, the side effects outweighed \\r\\nany benefit I got from it. I had trouble with restlessness, being tired constantly,\\r\\ndizziness, dry mouth, numbness and tingling in my feet, and horrible sweating. I am\\r\\nbeing weaned off of it now. Went from 60 mg to 30mg and now to 15 mg. I will be\\r\\noff completely in about a week. The fibro pain is coming back, but I would rather deal with it than the side effects.\"',\n",
              "  '\"I have been taking Mobic for over a year with no side effects other than an elevated blood pressure.  I had severe knee and ankle pain which completely went away after taking Mobic.  I attempted to stop the medication however pain returned after a few days.\"'],\n",
              " 'rating': [3.0, 10.0],\n",
              " 'date': ['November 7, 2011', 'June 5, 2013'],\n",
              " 'usefulCount': [13, 128]}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample = dataset[\"train\"].shuffle(seed=42).select(range(10))\n",
        "sample[1:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsAtQ7alalZF"
      },
      "source": [
        "### Normalize data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "7d7593f76f654499a7eb9e084e209f0b",
            "b6533cf7fa574f72b54f63509b5a1ac6",
            "13dfac508a074301a287557f4cdb5850",
            "386035e28b53434eab0fc3c70aa71c24",
            "30fad6e0715a49098f0799e3ad88e989",
            "dd764d719ad649d8a4e092611a6d6cc5",
            "54aad66686ee466b9c3fb3c4bf2a7e2b",
            "664e66ab727c40a980add68918c4948f",
            "43d23d276a99428caa6863c01e7d559e",
            "906f0bbcc26544b1866ce15006bf4f7a",
            "16c14189a0a249ce84aff9199a71252d",
            "bbb48adfe0ae49f0840e4df5de338d7b",
            "31815c2224024a928e8cfed77f96f2b9",
            "324233cb02314f5ab9aaebb5aebfccd1",
            "e1f4a4723ea94724a6c775e2c8b492b5",
            "b7c55d786e9d4bf8a36d027afc1d1b3f",
            "0e0d61acd5354fe1ae8320d68d8311a2",
            "6d01a713ed2242d79969f2a7ca6dbd1a",
            "86d18fe1424f462899e14719c0bd5968",
            "6f7dfe8ed45046b18693c5d6802cdfe0",
            "fc708e1aaf2d42fd99a032613d8fc4cc",
            "2de1cce6cd8b40bcbd1441d2b27334eb"
          ]
        },
        "id": "lMg0-EuKYgOq",
        "outputId": "82108df5-aa27-49a1-8542-e3448a455417"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d7593f76f654499a7eb9e084e209f0b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/161297 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bbb48adfe0ae49f0840e4df5de338d7b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/53766 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# we want to conver \"condition\" to. lower\n",
        "# First we need to remove none items\n",
        "dataset = dataset.filter(lambda row: row[\"condition\"] is not None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "f09f5e9095fc457eb131219e15c21158",
            "d06a3ed55f2e42e6a9678074465a9b53",
            "4295f4cbf7114cbdabcb39bbc5b368c6",
            "ceb8d09480b74c84812269b6e2110505",
            "94a705b80d854d2eb4f9e87e3a29e844",
            "0b27ddf17e2d495ca0bcb1bfb09982fe",
            "15de3e5f881c48b69134a4dd816669a3",
            "dbfc234dfd2f44a7ac49179b8f14e857",
            "4418c1b3b5ca4508a4d7c121eb2f26d6",
            "090eba83371b497981a1a2c1a491ac3f",
            "52ef627786154158bfe9eb7523437959",
            "784ca951c7744cda9f40e2280ba81ba0",
            "05243aa6dfbd4916bbdba59b4ed28e1a",
            "02cf1490961c4d6f90ef9bf3e0751e48",
            "1173a0b5f8d945e48840a3e6f8e752c4",
            "960bef29acf347c5b8bc4be163d16ace",
            "10bbf70299614dbba3fc0aead603bc25",
            "0b943125a8524757a193d77a07ed00a3",
            "a2e0744382ed48e8a33a5beb19b7c0d7",
            "b4f1cd88411f4437af6ab0a754d39329",
            "b5baaf88dcee4140bc0d24547cdd9058",
            "fe318336342c4f709f7b5cd78e398e42"
          ]
        },
        "id": "qMu4o-qSaLjP",
        "outputId": "681969c3-1212-4b3b-cc2e-0e0edca1a734"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f09f5e9095fc457eb131219e15c21158",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/160398 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "784ca951c7744cda9f40e2280ba81ba0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/53471 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# When we use batch, it feeds data in a list, so we can not map a list to lower()\n",
        "# dataset = dataset.map(lambda row: {\"condition\": row[\"condition\"].lower()})\n",
        "\n",
        "# If you want to use batch:\n",
        "dataset = dataset.map(\n",
        "    lambda row: {\"condition\": [item.lower() for item in row[\"condition\"]]}, batched=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "540ff086d8464853a049c4194cbd3bd4",
            "b3b01b68d0154c3b93af51665228ddd9",
            "9a069f329e9e44a7a98f5071bc641992",
            "6f8c82d743454462bfe11574d24923fc",
            "43bd6a38bdcc46149b7d8f47d5fe7898",
            "0d52ac2c517140c5a385ec921aac607f",
            "31b3d7fa592d41c9a86d747b66be634d",
            "7030baa06db84f36b18e5fc188bbc401",
            "20044ce7127d43c4ada383f60996c738",
            "912a9a90845446b991a2d94318e1298b",
            "5c77c8f7b9a24d82914eefe7d0314262",
            "7c18c579a76b4473a4d111316137afdc",
            "1cf26aedc20e4f99b91bf1ee55a3b5a3",
            "ab405ba2a4fd4ad88312f7b735c418cf",
            "ce28a640326346f09245adb1a5f31301",
            "e1de910d8cb14618a2c245d013a82776",
            "aaf13006b80a424fa9e0140d9e4b6ead",
            "fdebad17b4a74ef6b125c3eeffca9d3b",
            "fad7a30f946440909bcb3d163560b986",
            "2466447e684641cc82c1eb25508ea596",
            "8f7d59a0867843c7863658454fa41914",
            "c4c3deb2b691443496f3de5acca518e4"
          ]
        },
        "id": "rA23M4T9a9Gb",
        "outputId": "a17722b9-ccaf-4fd4-ae28-d4d4cdbf97a3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "540ff086d8464853a049c4194cbd3bd4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/160398 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c18c579a76b4473a4d111316137afdc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/53471 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# To enable multiprocessing, use the `num_proc = 8`\n",
        "#       as long as the function you are using is not already doing some kind of multiprocessing of its own.\n",
        "dataset = dataset.map(lambda row: {\"review_length\": len(row[\"review\"].split())}, batch_size = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdmSUWM1dKgL",
        "outputId": "3b6268d8-0199-42f4-b792-ad24b6e82e46"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': 206461,\n",
              " 'drugName': 'Valsartan',\n",
              " 'condition': 'left ventricular dysfunction',\n",
              " 'review': '\"It has no side effect, I take it in combination of Bystolic 5 Mg and Fish Oil\"',\n",
              " 'rating': 9.0,\n",
              " 'date': 'May 20, 2012',\n",
              " 'usefulCount': 27,\n",
              " 'review_length': 17}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[\"train\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "edc29679e8c44ff4aa95193134fceda3",
            "c9a95ffdb3fa49bcad435e4a6ee67167",
            "661df490547a4bb38eee4615f8ba6dbb",
            "13c9134e462945bca5228b9eeea67836",
            "ee80d0818f1e4c6788766e05f0dabfec",
            "f0f45180e8aa4926844ab1d66edb7ddf",
            "7395553ab153411ab9521ab021f5bbb0",
            "4963a92b17724d15af4d9ace61383564",
            "ee6865cb7b2c47338273c950a5c1b653",
            "d2241c368a1c44fca91216cebbc46a62",
            "98ac14efe586431f916871bc9ffe454f",
            "5a71bd2d84054c29a4add85d1ea67348",
            "7721b56d6ad546e587a0b58db85295e6",
            "91be799df0f74cf49e6dfd87fecbf49b",
            "518e0a48a4954da793e341a2b071a66d",
            "8a717a4bc09243ea8abbebe9f7baf03c",
            "dc93c31ba1044ced9f4e7ae2544d7ef8",
            "60e39927ee164eada2fe072cf9f5868d",
            "c141f3f2f0a44c77983b96f2f1220b47",
            "e551f1e31c7a4962955e4cfb82e8dd18",
            "ed3b545b178947c7967c73e1d23010ee",
            "b5dd0ce8e7404cf2a74ea1867902d96f"
          ]
        },
        "id": "OdzylE2idZFM",
        "outputId": "bf72ed65-d699-4a39-f58e-9e57e0a859a0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "edc29679e8c44ff4aa95193134fceda3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/160398 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a71bd2d84054c29a4add85d1ea67348",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/53471 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# remove data with review length lower than 30\n",
        "dataset = dataset.filter(lambda row: row[\"review_length\"] > 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MILJyFa1dsDH",
        "outputId": "1c501108-fe62-4e07-df66-5987f64b74e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],\n",
              "        num_rows: 138514\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],\n",
              "        num_rows: 46108\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "613e72b676874256b8901e3840aded07",
            "f40666dcb7684df684ebfb1a27498785",
            "5db4e106dac54f0c87ddc8824952c895",
            "60ea3c565d8948c58dc5654f3d39aa0a",
            "0f16aadf1af34a8295641e3a271b8552",
            "cb21737b765b487aaebd432017a8018d",
            "b64c74e659ce444f9e0498b08cfddf24",
            "d208e8a5dd734763af481296758c25f8",
            "3300c61f4fc047dcb0a3824794c42a27",
            "5dbee447a4c64e0b8e5e448b77c2a250",
            "a7b5daec12b643e5952576e9a9b847e1",
            "6e1f56b84c6a41729ff06bcfd356d63a",
            "38a90b30c9714da89e4fcfd46a671782",
            "5db5b7bd5b2446b38d3b284b0d58eb30",
            "6f1afeb00a444b2f8c353eb8320458fc",
            "b75e21a5babf4712a2e38888a31fe95f",
            "76483ddd97594749aae7ed7b493f0701",
            "a5ee38dd69304fb59a9d4a939f48ebb0",
            "b95c697cc44a4573b9ec45f9385dcbf0",
            "91d26bd991ca42bbabc2ae69a66f6fdd",
            "94c1746e006849599af8b422ba940154",
            "2fb4f89b683f47098f5b88b594205aa5"
          ]
        },
        "id": "giiXSoq3dvFr",
        "outputId": "fd7fd668-084a-4b15-e4e8-3caf694ef299"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "613e72b676874256b8901e3840aded07",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/138514 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e1f56b84c6a41729ff06bcfd356d63a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/46108 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Remove HTML tags\n",
        "dataset = dataset.map(\n",
        "    lambda row: {\"review\": [html.unescape(item) for item in row[\"review\"]]}, batched = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVKPvxsZd8ZT"
      },
      "outputs": [],
      "source": [
        "# checkpoint = \"bert-base-cased\"\n",
        "checkpoint = \"distilgpt2\"\n",
        "# checkpoint = \"openai-community/gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7gBMGCuPnWq"
      },
      "outputs": [],
      "source": [
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "fe4213bf25c54d08997b96ab1486861c",
            "1f4fe78a3aab4f1ba59812788f202755",
            "532410790f48432381f34b1ae863a0f0",
            "8be0cf4a501c469788ce2f473b14fc76",
            "4d6e2c6cfa8848d9960d8c0b14929f23",
            "e8fabea157cb4967ac0de20e4d29f1e8",
            "54fa5d0b4e0244d68ae92a59faf48698",
            "93542287b6f24c7f9e67ff38820ae8ae",
            "b6b2731f918f47bf935c2bc90efef829",
            "0850d031ea8144a390a2d5f558278bb8",
            "56cf07fa883d4b588fa77dc12cc67dc1",
            "fededa5c472a45b7a3cd37b4683a0dd9",
            "85fe5b08e2284a578cc3fcbc57a59c5e",
            "a3e7bd2fb42c4ecbb0f75daaf044004a",
            "5187548fb64e4e968067aa3a9680a5d6",
            "facb687003f947acba9070794b1483d5",
            "6e435b81f93f47c4b86e8b2f17926160",
            "f4d9f99b8739497cbd9b8fb64b739a6a",
            "505ee40780b94045b1add33b4190d30f",
            "ad2e0f3f7cfb47fe85f8372496019b54",
            "e9410382b8b849bf897030e22d4749fd",
            "38c132dac86e4a37ad5e6389d9a5ad5e"
          ]
        },
        "id": "7fLbLSd9mlON",
        "outputId": "e7458e40-26e3-4b8e-a188-394eb38a646f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe4213bf25c54d08997b96ab1486861c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/138514 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fededa5c472a45b7a3cd37b4683a0dd9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/46108 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# some sets became two features because it was tokenized to more than the maximum number of tokens we specified (128)\n",
        "# so we need to remove the columns\n",
        "\n",
        "def tokenize_and_split(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"review\"],\n",
        "        truncation = True,\n",
        "        padding = False,\n",
        "        max_length = 128,\n",
        "        return_overflowing_tokens = True,\n",
        "        return_tensors = None\n",
        "    )\n",
        "\n",
        "tokenized_dataset = dataset.map(\n",
        "    tokenize_and_split,\n",
        "    batched = True,\n",
        "    remove_columns = dataset['train'].column_names  # Remove old columns\n",
        ")\n",
        "\n",
        "\n",
        "# # Or making the old columns the same size as the new ones.\n",
        "# # This way we can keep original columns too\n",
        "# def tokenize_and_split(examples):\n",
        "#     result = tokenizer(\n",
        "#         examples[\"review\"],\n",
        "#         truncation = True,\n",
        "#         max_length = 128,\n",
        "#         return_overflowing_tokens = True,\n",
        "#     )\n",
        "#     # Extract mapping between new and old indices\n",
        "#     sample_map = result.pop(\"overflow_to_sample_mapping\")\n",
        "#     for key, values in examples.items():\n",
        "#         result[key] = [values[i] for i in sample_map]\n",
        "#     return result\n",
        "\n",
        "\n",
        "# tokenized_dataset = dataset.map(\n",
        "#     tokenize_and_split, batched = True #, remove_columns = dataset[\"train\"].column_names\n",
        "# )\n",
        "\n",
        "# # Remove unnecessary columns\n",
        "# columns_to_remove = ['id', 'drugName', 'condition', 'date', 'usefulCount', 'review_length', 'review']\n",
        "# tokenized_dataset = tokenized_dataset.remove_columns(columns_to_remove)\n",
        "# tokenized_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE757fL0qHoC",
        "outputId": "071b6aa8-28ff-4bde-f976-9b6d1c601b4e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'overflow_to_sample_mapping'],\n",
              "        num_rows: 200764\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'overflow_to_sample_mapping'],\n",
              "        num_rows: 66906\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3SRtJ9RoV2L"
      },
      "source": [
        "#### Change dataset format\n",
        "\n",
        "`Dataset.set_format()` function. This function only changes the output format of the dataset, so you can easily switch to another format without affecting the underlying data format, which is `Apache Arrow`.\n",
        "\n",
        "```py\n",
        "dataset.set_format(\"pandas\")\n",
        "\n",
        "# revert back\n",
        "dataset.reset_format()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbEAou5fnwo2",
        "outputId": "8b7dd1e2-2b59-4ed8-e063-79a9c5ac6275"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'overflow_to_sample_mapping'],\n",
              "        num_rows: 160611\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'overflow_to_sample_mapping'],\n",
              "        num_rows: 40153\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'overflow_to_sample_mapping'],\n",
              "        num_rows: 66906\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create validation split\n",
        "dataset_clean = tokenized_dataset[\"train\"].train_test_split(train_size=0.8, seed=42)\n",
        "\n",
        "# Rename the default \"test\" split to \"validation\"\n",
        "dataset_clean[\"validation\"] = dataset_clean.pop(\"test\")\n",
        "\n",
        "# Add the \"test\" set to our `DatasetDict`\n",
        "dataset_clean[\"test\"] = tokenized_dataset[\"test\"]\n",
        "dataset_clean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-knHTzJeqW9b"
      },
      "source": [
        "### Save file\n",
        "\n",
        "Data format | Function\n",
        "------------|---------\n",
        "Arrow | Dataset.save_to_disk()\n",
        "CSV | Dataset.to_csv()\n",
        "JSON | Dataset.to_json()\n",
        "\n",
        "### Load\n",
        "\n",
        "```py\n",
        "from datasets import load_from_disk\n",
        "\n",
        "ataset_reloaded = load_from_disk(\"data\")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZfwhvr91-UA"
      },
      "source": [
        "## LoRA\n",
        "\n",
        "LoRA can be applied to any subset of weight matrices in a neural network to reduce the number of trainable parameters.\n",
        "\n",
        "However, in Transformer models LoRA is typically applied to **attention blocks only**.\n",
        "\n",
        "<br>\n",
        "\n",
        "> [LoRA](https://huggingface.co/docs/peft/main/en/conceptual_guides/lora) <br>\n",
        "[conceptual guide](https://huggingface.co/docs/peft/main/en/conceptual_guides/adapter) <br>\n",
        "[QLoRA](https://huggingface.co/docs/peft/en/developer_guides/quantization)\n",
        "\n",
        "<br>\n",
        "\n",
        "- `merge_adapter()` to merge the LoRa layers into the base model.\n",
        "- `unmerge_adapter()` to unmerge the LoRa layers from the base model.\n",
        "- `unload()` to get back the base model without the merging of the active lora modules.\n",
        "- `delete_adapter()` to delete an existing adapter.\n",
        "- `add_weighted_adapter()` to combine multiple LoRAs into a new adapter based on the user provided weighing scheme."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpghTH55A0HI"
      },
      "source": [
        "### Workflow:\n",
        "\n",
        "1. Instantiate a base model.\n",
        "2. Create a configuration (`LoraConfig`) where you define LoRA-specific parameters.\n",
        "3. Wrap the base model with `get_peft_model()` to get a trainable PeftModel.\n",
        "4. Train the PeftModel as you normally would train the base model.\n",
        "\n",
        "### `LoraConfig`\n",
        "\n",
        "\n",
        "- $r$: the rank of the update matrices\n",
        "- `lora_alpha`: LoRA scaling factor.\n",
        "- `bias`: Specifies if the bias parameters should be trained.'none', 'all' or 'lora_only'.\n",
        "- `use_rslora`: When set to True, uses Rank-Stabilized LoRA which sets the adapter scaling factor to $\\frac{\\text{lora_alpha}}{\\sqrt(r)}$. Otherwise, $\\frac{\\text{lora_alpha}}{r}$.\n",
        "- `modules_to_save`: List of modules apart from LoRA layers to be set as trainable and saved in the final checkpoint. default modelâ€™s custom head.\n",
        "- `layers_to_transform`: List of layers to be transformed by LoRA. If not specified, all layers in target_modules are transformed.\n",
        "- `target_modules`\n",
        "\n",
        "> **Query**: Controls what parts of the input the model focuses on.<br>\n",
        "**Value**: Controls how the attended information is transformed\n",
        "\n",
        "Check available modules:\n",
        "```py\n",
        "model = AutoModelForCausalLM.from_pretrained(\"your-model-name\")\n",
        "for name, module in model.named_modules():\n",
        "    if any(x in name for x in [\"query\", \"key\", \"value\", \"q_proj\", \"k_proj\", \"v_proj\"]):\n",
        "        print(name)\n",
        "```\n",
        "\n",
        "<br>\n",
        "\n",
        "`init_lora_weights`:\n",
        "- default Kaiming-uniform for weight A and initializing weight B as zeros.\n",
        "- init_lora_weights=\"gaussian\", initializing weight A with a Gaussian distribution .\n",
        "- When quantizing the base model, e.g. for `QLoRA` training, consider using the `LoftQ` initialization,\n",
        "\n",
        "```py\n",
        "loftq_config = LoftQConfig(\n",
        "    loftq_bits=4,   # Main quantization bit-width\n",
        "    loftq_iter=1,   # Number of alternating optimization iterations\n",
        "    loftq_recode_interval=1,    # How often to recode/update during optimization\n",
        "    loftq_recode_ratio=0.25,    # Ratio of columns to recode in each iteration\n",
        "    base_bits=None, # Base bits for non-quantized parts (None = use original precision)\n",
        "    loftq_layers=None # Specific layers to apply LoftQ to (None = all applicable layers)\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95jqJWCdDwM8"
      },
      "outputs": [],
      "source": [
        "# !pip install bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CB7oNZmYo4M_"
      },
      "outputs": [],
      "source": [
        "from peft import LoftQConfig, LoraConfig, get_peft_model\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling, BitsAndBytesConfig\n",
        ")\n",
        "\n",
        "\n",
        "checkpoint = \"distilgpt2\"\n",
        "# checkpoint = \"openai-community/gpt2\"\n",
        "# bnb_config = BitsAndBytesConfig(load_in_8bit=True)\n",
        "# base_model = AutoModelForCausalLM.from_pretrained(checkpoint, quantization_config=bnb_config)\n",
        "base_model = AutoModelForCausalLM.from_pretrained(checkpoint)  # don't quantize here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "e5lqu3xfDHfD"
      },
      "outputs": [],
      "source": [
        "# Check model modules\n",
        "# for name, module in base_model.named_modules():\n",
        "#     print(name, module)\n",
        "#     print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NmC3bxg92Ns",
        "outputId": "10885c3c-3e15-4422-de26-1c48086337cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 811,008 || all params: 82,723,584 || trainable%: 0.9804\n"
          ]
        }
      ],
      "source": [
        "# loftq_config = LoftQConfig(loftq_bits=4)           # set 4bit quantization\n",
        "lora_config = LoraConfig(\n",
        "    r = 16,\n",
        "    lora_alpha = 16,\n",
        "    target_modules = [\"c_attn\", 'c_proj'],\n",
        "    lora_dropout = 0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    # init_lora_weights = \"loftq\",\n",
        "    # loftq_config=loftq_config\n",
        ")\n",
        "\n",
        "peft_model = get_peft_model(base_model, lora_config)\n",
        "peft_model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "YmbYYnTclHQJ"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# peft_model.to(device).device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "B9BmaAkneEoI"
      },
      "outputs": [],
      "source": [
        "# # Check model expectation\n",
        "# print(\"Model forward signature:\")\n",
        "# print(base_model.forward.__doc__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "0pDLrIwzcXez"
      },
      "outputs": [],
      "source": [
        "# Use language modeling data collator\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer = tokenizer,\n",
        "    mlm = False  # Not masked language modeling\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRp-Rdx0ipBH"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir = \"./my_model\",\n",
        "    remove_unused_columns = True,\n",
        "    eval_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    learning_rate = 5e-3,\n",
        "    weight_decay = 0.01,\n",
        "    per_device_train_batch_size = batch_size,\n",
        "    gradient_accumulation_steps = 4,\n",
        "    per_device_eval_batch_size = batch_size,\n",
        "    fp16 = True,\n",
        "    num_train_epochs = 5,\n",
        "    logging_steps = 10,\n",
        "    load_best_model_at_end = True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PU3sLNlBajlz"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model = peft_model,\n",
        "    args = args,\n",
        "    train_dataset = dataset_clean['train'],\n",
        "    eval_dataset = dataset_clean['validation'],\n",
        "    processing_class = tokenizer,\n",
        "    data_collator = data_collator,  # Add data collator for LM\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1V97HGi7ajjF"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "results = trainer.evaluate()\n",
        "print(f\"Eval loss: {results['eval_loss']:.3f}\")\n",
        "print(f\"Perplexity: {math.exp(results['eval_loss']):.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmZYVVBgrFTl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kTXhzmKrFP5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTBmD9qYrFMB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAj5wIiDrFHk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAF8xOUNajgK"
      },
      "outputs": [],
      "source": [
        "# # Use a pipeline as a high-level helper\n",
        "# from transformers import pipeline\n",
        "\n",
        "# pipe = pipeline(\"text-generation\", model = peft_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEOxNTNBqUAw"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "eli5 = load_dataset(\"dany0407/eli5_category\", split=\"train[:5000]\")\n",
        "eli5 = eli5.train_test_split(test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tyg5FzboqT9g"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilgpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBwyakh6qT6e"
      },
      "outputs": [],
      "source": [
        "eli5 = eli5.flatten()\n",
        "eli5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XNBN4lSKqT3O"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    return tokenizer([\" \".join(x) for x in examples[\"answers.text\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0qifl5Iqa6N"
      },
      "outputs": [],
      "source": [
        "tokenized_eli5 = eli5.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    num_proc=4,\n",
        "    remove_columns=eli5[\"train\"].column_names,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9oVwyabOqb-5"
      },
      "outputs": [],
      "source": [
        "block_size = 128\n",
        "\n",
        "\n",
        "def group_texts(examples):\n",
        "    # Concatenate all texts.\n",
        "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
        "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
        "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
        "    # customize this part to your needs.\n",
        "    if total_length >= block_size:\n",
        "        total_length = (total_length // block_size) * block_size\n",
        "    # Split by chunks of block_size.\n",
        "    result = {\n",
        "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
        "        for k, t in concatenated_examples.items()\n",
        "    }\n",
        "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tz6Ud5Nhqvz9"
      },
      "outputs": [],
      "source": [
        "lm_dataset = tokenized_eli5.map(group_texts, batched=True, num_proc=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7q2Wz5x_qx02"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "f2a0081030bf45ef9296b70a5d412a04",
            "a1973e4ac73d463d9403151cac418dd1",
            "58b59f7371c74767b2495889b15f4010",
            "e929998a73df496a9d48af1226d329cd",
            "f0f4c75e673f4bccaae2ee4a0ae64d1b",
            "886e137e02984318972b6e019d36ec17",
            "f72f7c78fff04a0dbbd4d6c3674b5d9f",
            "d3289a9f010f4fc69bb20c657a57bea9",
            "d6dec835ea69444b8b19db62a1dee0b1",
            "58117eb91e0845a7a438f04636078a68",
            "209d73b68d434df893a1d3dbe5f156a0",
            "9c1be2fc759449899ba61b1b554df5ae",
            "e453cd53b4924948ab7d2642c689b0c5",
            "dcd41acbe1f449dbaba2f124dacf505d",
            "55057c0f63174767b87927581db42b69",
            "e9dd8861efa24400a7714b9d21a3c70c",
            "44ec18b879a446ee96b9617e420b21ab",
            "fe37a146fdc446028f7cb902235a860f",
            "3cd9f636c9fe4725becad7cde2ecfc18",
            "22526d6ff5c8448f8f3c62c098308918",
            "f88eec8d73724840b8b2f95715b0bf2b",
            "cc7ff760e6b24c2eb9155552d7f124a7"
          ]
        },
        "id": "dXxzTpQ4q2BZ",
        "outputId": "d7b1d88f-8169-4f85-c7b9-2b0cbd792a53"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2a0081030bf45ef9296b70a5d412a04",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c1be2fc759449899ba61b1b554df5ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"distilbert/distilgpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUsJLmn6q8BD"
      },
      "outputs": [],
      "source": [
        "lm_dataset['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQBv5mQDq2Y-"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"my_awesome_eli5_clm-model\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    # push_to_hub=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=lm_dataset[\"train\"],\n",
        "    eval_dataset=lm_dataset[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnPMDgMWq4om"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
