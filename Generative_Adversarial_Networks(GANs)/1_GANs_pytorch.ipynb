{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BimOnXEkudn"
      },
      "source": [
        "# **Generative Adversarial Networks(GANs)**\n",
        "<img align='right' width='800' src=\"https://cdn-images-1.medium.com/v2/resize:fit:851/0*pPEL7ryJR51VpnDO.jpg\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "LxX-JnAN9nb0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "e0sKi5Ub-W6m"
      },
      "outputs": [],
      "source": [
        "# Visioalize the data\n",
        "def show(tensor, ch=1, size=(28, 28), num_to_display=16):\n",
        "    \"\"\"\n",
        "    Inputs would be tensors with (batch_size, channel, height, weight) dimensions.\n",
        "    First, we detach() the tensor, so it doesn't require grade any more.\n",
        "    Then send it to cpu() to make sure the tensor isn't on a different device.\n",
        "    Matplotlib shows images in (height, width, channel) dimention, so the images permute to match the criteria.\n",
        "    \"\"\"\n",
        "    images = tensor.detach().cpu().view(-1, ch, *size)\n",
        "    grid = make_grid(images[:num_to_display], nrow=4).permute(1, 2, 0)\n",
        "    plt.axis(False)\n",
        "    plt.imshow(grid)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "OoAz0BTm9p9V"
      },
      "outputs": [],
      "source": [
        "def get_data(data=MNIST, bs=128):\n",
        "    \"\"\"\n",
        "    From torchvision.datasets we can get different datasets.\n",
        "    For training GANs, we don't need test datasets; just train sets will be enough.\n",
        "    \"\"\"\n",
        "    transform = torchvision.transforms.Compose([\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        torchvision.transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "    train_set = MNIST('.',\n",
        "                      train=True,\n",
        "                      transform=ToTensor(),\n",
        "                      download=True)\n",
        "\n",
        "    # group the data in different batch size\n",
        "    data_loader = DataLoader(train_set, bs, shuffle=True)\n",
        "\n",
        "    return data_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yh-vz_-87Ag7",
        "outputId": "fb6a52b1-dca6-435a-c96f-68573c698fa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Availabe device is:  cuda\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "EPOCH = 50\n",
        "Z_DIM = 100\n",
        "LR = 1e-4\n",
        "BS = 128\n",
        "\n",
        "data = get_data(MNIST, BS)\n",
        "C, H, W = next(iter(data))[0][0].shape\n",
        "loss_func = nn.BCELoss()\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Availabe device is: \", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFJJMbF8nJ4B"
      },
      "source": [
        "## **Discriminator and Generator Networkrs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "8pC2OWzi6n81"
      },
      "outputs": [],
      "source": [
        "# Generator\n",
        "class Generator(nn.Module):\n",
        "    \"\"\"\n",
        "    A class representing the generator component of a Generative Adversarial Network (GAN).\n",
        "\n",
        "    Parameters:\n",
        "        z_dim (int): The dimension of the input noise vector.\n",
        "        hidden_dim (int): The dimension of the hidden layers in the generator.\n",
        "        out_dim (int): The dimension of the output data (flattened).\n",
        "\n",
        "    Methods:\n",
        "        forward(nois): Forward pass function of the generator.\n",
        "        _gen_block(in_dim, out): Helper function to create a generator block.\n",
        "\n",
        "    Attributes:\n",
        "        gen (nn.Sequential): The sequential model representing the generator architecture.\n",
        "    \"\"\"\n",
        "    def __init__(self, z_dim=100, hidden_dim=128, out_dim=28*28):\n",
        "        super().__init__()\n",
        "        self.gen = nn.Sequential(\n",
        "            self._gen_block(z_dim, hidden_dim),\n",
        "            self._gen_block(hidden_dim, hidden_dim*2),\n",
        "            self._gen_block(hidden_dim*2, hidden_dim*4),\n",
        "            self._gen_block(hidden_dim*4, hidden_dim*8),\n",
        "            self._gen_block(hidden_dim*8, out_dim),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, noise):\n",
        "        return self.gen(noise)\n",
        "\n",
        "    def _gen_block(self, in_dim, out):\n",
        "        return nn.Sequential(\n",
        "            nn.Linear(in_dim, out),\n",
        "            nn.BatchNorm1d(out),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "# Discriminator\n",
        "class Discriminator(nn.Module):\n",
        "    \"\"\"\n",
        "    A class representing the discriminator component of a Generative Adversarial Network (GAN).\n",
        "\n",
        "    Parameters:\n",
        "        in_dim (int): The dimension of the input data.\n",
        "        hidden_dim (int): The dimension of the hidden layers in the discriminator.\n",
        "        out_dim (int): The dimension of the output data (single value for binary classification).\n",
        "\n",
        "    Methods:\n",
        "        forward(x): Forward pass function of the discriminator.\n",
        "        _disc_block(in_dim, out): Helper function to create a discriminator block.\n",
        "\n",
        "    Attributes:\n",
        "        disc (nn.Sequential): The sequential model representing the discriminator architecture.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_dim=28*28, hidden_dim=128, out_dim=1):\n",
        "        super().__init__()\n",
        "        self.disc = nn.Sequential(\n",
        "            self._disc_block(in_dim, hidden_dim*4),\n",
        "            self._disc_block(hidden_dim*4, hidden_dim*2),\n",
        "            self._disc_block(hidden_dim*2, hidden_dim),\n",
        "            nn.Linear(hidden_dim, out_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 1*28*28) # Flatten input data to a Linear layer\n",
        "        return self.disc(x)\n",
        "\n",
        "    def _disc_block(self, in_dim, out):\n",
        "        return nn.Sequential(\n",
        "            nn.Linear(in_dim, out),\n",
        "            nn.BatchNorm1d(out),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definition of a lambda function to generate random noise samples for a GAN\n",
        "gen_noise = lambda number, z_dim: torch.randn(number, z_dim).to(device)\n",
        "\n",
        "# Description:\n",
        "# This lambda function is used to create random noise samples, commonly employed in training Generative Adversarial Networks (GANs).\n",
        "# It takes two parameters:\n",
        "#   - number: An integer indicating the number of noise samples to generate.\n",
        "#   - z_dim: An integer representing the dimensionality of each noise sample.\n",
        "# The function returns a PyTorch tensor of shape (number, z_dim) containing random noise samples drawn from a standard normal distribution with mean 0 and standard deviation 1.\n",
        "# Additionally, the .to(device) method at the end of the function ensures that the generated tensor is moved to the specified device for computation, assuming 'device' is defined elsewhere in the code. This is typically done to utilize GPU acceleration for faster processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "n166tyLBAtgY"
      },
      "outputs": [],
      "source": [
        "gen_noise = lambda number, z_dim: torch.randn(number, z_dim).to(device)\n",
        "\n",
        "gen = Generator().to(device)\n",
        "gen_opt = torch.optim.Adam(gen.parameters(), lr=LR)\n",
        "#If we need to change learning rate during training we can use lr_scheduler function in torch.optim\n",
        "gen_exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(gen_opt, step_size=10, gamma=0.5)\n",
        "\n",
        "disc = Discriminator().to(device)\n",
        "disc_opt = torch.optim.Adam(disc.parameters(), lr=LR)\n",
        "disc_exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(disc_opt, step_size=10, gamma=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ic1f8katBEbX"
      },
      "outputs": [],
      "source": [
        "#Check the data\n",
        "x, y = next(iter(data))\n",
        "print(\"Shape of dataset images: \", x.shape)\n",
        "print(\"label of images\", y[:16])\n",
        "\n",
        "noise = gen_noise(BS, Z_DIM)\n",
        "fake = gen(noise)\n",
        "show(x, ch=C, size=(H, W))\n",
        "show(fake)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNTBiqHBZ1XZ"
      },
      "source": [
        "## **BCELoss**\n",
        "$$\n",
        "    \\large -\\frac{1}{n}\\sum_{i=1}^{n}{-[y_i\\log(𝚢^{̂}_i) + (1-y_i)\\log(1-y^{̂}_i)]}\n",
        "$$\n",
        "\n",
        "<br>\n",
        "\n",
        "**Generator Loss**\\\n",
        "<br>\n",
        "Generator wants to fool the Discriminator so in loss calculation we consider **one** matrix to calculate the loss so the **BCE** formular will be:\n",
        "\n",
        "$$\n",
        "    \\frac{1}{n}\\sum_{i=1}^{n}{(\\log(𝚢^{̂}_i))}\n",
        "$$\n",
        "\n",
        "where the $y^̂$ is the last output of the Discriminator:\n",
        "\n",
        "$$\n",
        "   \\large 𝒁 ⟶ Generator \\xrightarrow[\\text{}]{\\text{G(z)}} Discriminator \\xrightarrow[\\text{}]{\\text{D(G(z))}} -\\frac{1}{n}\\sum_{i=1}^{n}{(\\log(D(G(z))))}\n",
        "$$\n",
        "\n",
        "**Discriminator Loss**\n",
        "<br>\n",
        "**one** matrix to calculate the loss for **real** input and **zeors** matrix to calculate the loss for **fake** input which is the output of generator so the **BCE** formular will be:\n",
        "\n",
        "<br>\n",
        "\n",
        "$\\text{When label is 1 (for real ones)}:$\n",
        "$$\n",
        "    \\frac{1}{n}\\sum_{i=1}^{n}{(\\log(𝚢^{̂}_i))}\n",
        "$$\n",
        "\n",
        "<br>\n",
        "\n",
        "$\\text{When label is 0 (for generated images)}:$\n",
        "$$\n",
        "    \\frac{1}{n}\\sum_{i=1}^{n}{(\\log(1- 𝚢^{̂}_i))}\n",
        "$$\n",
        "\n",
        "where the $y^̂$ is the last output of the Discriminator:\n",
        "\n",
        "$$\n",
        "    \\large -\\frac{1}{n}\\sum_{i=1}^{n}{-[\\log(D(x)) + \\log(1 - D(G(z)))]}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "2esxTiPWDQSt"
      },
      "outputs": [],
      "source": [
        "#This the the most important part of the training\n",
        "def gen_loss_func(gen_net, disc_net, loss_func, num, z_dim):\n",
        "    \"\"\"\n",
        "    Calculate the generator's loss based on the provided discriminator and loss function.\n",
        "\n",
        "    Parameters:\n",
        "        gen_net (nn.Module): The generator network.\n",
        "        disc_net (nn.Module): The discriminator network.\n",
        "        loss_func: The loss function used for calculating the loss.\n",
        "        num (int): The number of noise samples to generate.\n",
        "        z_dim (int): The dimensionality of the noise vector.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The calculated generator loss.\n",
        "\n",
        "    \"\"\"\n",
        "    # Generate noise samples\n",
        "    noise = gen_noise(num, z_dim)\n",
        "    \n",
        "    # Generate fake images using the generator\n",
        "    fake = gen_net(noise)\n",
        "    \n",
        "    # Pass fake images through the discriminator\n",
        "    pred = disc_net(fake)\n",
        "    \n",
        "    # Create target labels (all ones for the generator)\n",
        "    real = torch.ones_like(pred)\n",
        "    \n",
        "    # Calculate generator loss using the provided loss function\n",
        "    return loss_func(pred, real)\n",
        "\n",
        "\n",
        "\n",
        "def disc_loss_func(gen_net, disc_net, loss_func, image, num, z_dim):\n",
        "    \"\"\"\n",
        "    Calculate the discriminator's loss based on the provided generator, discriminator, image, and loss function.\n",
        "\n",
        "    Parameters:\n",
        "        gen_net (nn.Module): The generator network.\n",
        "        disc_net (nn.Module): The discriminator network.\n",
        "        loss_func: The loss function used for calculating the loss.\n",
        "        image (torch.Tensor): Real images used for training the discriminator.\n",
        "        num (int): The number of noise samples to generate.\n",
        "        z_dim (int): The dimensionality of the noise vector.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The calculated discriminator loss.\n",
        "\n",
        "    \"\"\"\n",
        "    # Generate noise samples\n",
        "    noise = gen_noise(num, z_dim)\n",
        "    \n",
        "    # Generate fake images using the generator\n",
        "    fake = gen_net(noise)\n",
        "    \n",
        "    # Pass fake images (with detached gradients) and real images through the discriminator\n",
        "    fake_pred = disc_net(fake.detach())  # detach() the generator output to prevent gradient flow\n",
        "    real_pred = disc_net(image)\n",
        "    \n",
        "    # Compute losses for real and fake images\n",
        "    loss_real = loss_func(real_pred, torch.ones_like(real_pred))  # real images should be classified as real (1)\n",
        "    loss_fake = loss_func(fake_pred, torch.zeros_like(fake_pred))  # fake images should be classified as fake (0)\n",
        "    \n",
        "    # Combine real and fake losses and average them\n",
        "    return (loss_real + loss_fake) / 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "-_yNA6v3TXE9"
      },
      "outputs": [],
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "!rm -r /content/runs\n",
        "writer = SummaryWriter(\"/content/runs\")\n",
        "writer_fake = SummaryWriter(\"/content/runs/fake\")\n",
        "writer_real = SummaryWriter(\"/content/runs/real\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCFEe-UwUDS-"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=runs\n",
        "# %reload_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMoMG6MvLSWx"
      },
      "outputs": [],
      "source": [
        "step = 0\n",
        "for epoch in range(EPOCH):\n",
        "    mean_gen_loss = 0\n",
        "    mean_disc_loss = 0\n",
        "    print(f\"\\nEpoch: {epoch + 1}\")\n",
        "\n",
        "    for batch, (real, _) in enumerate(tqdm(data)):\n",
        "        real = real.to(device)\n",
        "\n",
        "        # Train the discriminator\n",
        "        disc_loss = disc_loss_func(gen, disc, loss_func, real, BS, Z_DIM)\n",
        "        disc_opt.zero_grad()\n",
        "        disc_loss.backward(retain_graph=True)  # Retain graph for the generator\n",
        "        disc_opt.step()\n",
        "\n",
        "        # Train the generator\n",
        "        gen_loss = gen_loss_func(gen, disc, loss_func, BS, Z_DIM)\n",
        "        gen_opt.zero_grad()\n",
        "        gen_loss.backward()\n",
        "        gen_opt.step()\n",
        "\n",
        "        if batch % 150 == 0 and batch != 0:\n",
        "            # Generate fake images and visualize\n",
        "            with torch.no_grad():\n",
        "                step += 1\n",
        "                fake = gen(gen_noise(BS, Z_DIM)).view(-1, C, H, W)\n",
        "                image = real.view(-1, C, H, W)\n",
        "                real_grid = make_grid(image[:24], normalize=True)\n",
        "                fake_grid = make_grid(fake[:24], normalize=True)\n",
        "\n",
        "                writer_fake.add_image(\n",
        "                    \"MNIST fake image\", fake_grid, global_step=step\n",
        "                )\n",
        "                writer_real.add_image(\n",
        "                    \"MNIST real image\", real_grid, global_step=step\n",
        "                )\n",
        "\n",
        "    # Compute mean losses for discriminator and generator\n",
        "    disc_loss /= len(data)\n",
        "    gen_loss /= len(data)\n",
        "    print(f'  Discriminator Loss: {disc_loss:.4f} -- Generator Loss: {gen_loss:.4f}')\n",
        "\n",
        "    # Adjust learning rates using schedulers\n",
        "    gen_exp_lr_scheduler.step()\n",
        "    disc_exp_lr_scheduler.step()\n",
        "\n",
        "    # Write losses to tensorboard\n",
        "    writer.add_scalar(\"Loss/Disc\", disc_loss, epoch)\n",
        "    writer.add_scalar(\"Loss/Gen\", gen_loss, epoch)\n",
        "\n",
        "    # Print learning rates every 10 epochs\n",
        "    if epoch % 10 == 0 and epoch > 0:\n",
        "        print(f\"  >>> Discriminator Learning Rate: {disc_opt.param_groups[0]['lr']}\")\n",
        "        print(f\"  >>> Generator Learning Rate: {gen_opt.param_groups[0]['lr']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRVD-zsLQYvT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
