{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Generative Adversarial Networks(GANs)**\n",
        "<img align='right' width='500' src=\"https://cdn-images-1.medium.com/v2/resize:fit:851/0*pPEL7ryJR51VpnDO.jpg\">"
      ],
      "metadata": {
        "id": "hwkXZNWBnlgU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bS4WCgitYCFQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor, Normalize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "EPOCH = 15\n",
        "Z_DIM = 100\n",
        "LR = 2e-4\n",
        "BS = 128\n",
        "C, H, W =1, 32, 32\n",
        "\n",
        "loss_func = nn.BCELoss()\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Availabe device is: \", device)"
      ],
      "metadata": {
        "id": "IZYBnBDhMHbU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3cdfcf5-903a-41c0-e9c6-bbfb4c04b537"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Availabe device is:  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visioalize the data\n",
        "def show(tensor, ch=C, size=(H, W), num_to_display=16):\n",
        "    \"\"\"\n",
        "    Inputs would be tensor with (batch_size, channel, height, weight) dimention\n",
        "    First we detach() tensor so because it's not require grade any more,\n",
        "    Then send it to cpu() to make sure the tensor doesn't on different device\n",
        "    Matplotlib show images in (height, width, channel) dimention so the images permute to match the criteria\n",
        "    \"\"\"\n",
        "    images = tensor.detach().cpu().view(-1, ch, *size)\n",
        "    grid = make_grid(images[:num_to_display], nrow=4).permute(1, 2, 0)\n",
        "    plt.axis(False)\n",
        "    plt.imshow(grid)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "-2eJzqwGYGHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(data=MNIST, bs=128):\n",
        "    \"\"\"\n",
        "    From torchvision.datasets we can get different dataset\n",
        "    for training GANs we don't need test datasets just trian sets will be enough\n",
        "    \"\"\"\n",
        "    transform = torchvision.transforms.Compose([\n",
        "        torchvision.transforms.Resize(H),\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        torchvision.transforms.Normalize(\n",
        "            [0.5 for _ in range(C)], [0.5 for _ in range(C)]\n",
        "        )\n",
        "    ])\n",
        "    train_set = MNIST('.',\n",
        "                      train=True,\n",
        "                      transform=transform,\n",
        "                      download=True)\n",
        "\n",
        "    # group the data in different batch size\n",
        "    data_loader = DataLoader(train_set, bs, shuffle=True)\n",
        "\n",
        "    return data_loader"
      ],
      "metadata": {
        "id": "RwPgf1zroWTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = get_data(MNIST, BS)\n",
        "C, H, W = next(iter(data))[0][0].shape"
      ],
      "metadata": {
        "id": "UpigIPmuJ0mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Discriminator and Generator Networkrs**\n",
        "**DCGAN** stands for Deep Convolutional Generative\n",
        "Adversarial Network. It is a type of GAN that uses convolutional layers in both the generative and discriminative models.## **Discriminator and Generator Networkrs**"
      ],
      "metadata": {
        "id": "2k9ml0dhouob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Generator\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim=100, hidden_ch=8, out_ch=C):\n",
        "        super().__init__()\n",
        "        self.gen = nn.Sequential(\n",
        "            self._gen_block(z_dim, hidden_ch*8, 4, 1, 0),\n",
        "            self._gen_block(hidden_ch*8, hidden_ch*4, 4 , 2 , 1),\n",
        "            self._gen_block(hidden_ch*4, hidden_ch*2, 4, 2, 1),\n",
        "            nn.ConvTranspose2d(hidden_ch*2, out_ch, 4, 2, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, noise):\n",
        "        noise = noise.view(BS, Z_DIM, 1, 1)\n",
        "        return self.gen(noise)\n",
        "\n",
        "    def _gen_block(self, in_ch, out_ch, kernel, stride, padding):\n",
        "        return nn.Sequential(\n",
        "            nn.ConvTranspose2d(\n",
        "                in_ch, out_ch, kernel, stride, padding, bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "#Discriminator\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, img_ch=1, hidden_ch=8, out_dim=1):\n",
        "        super().__init__()\n",
        "        self.disc = nn.Sequential(\n",
        "            nn.Conv2d(img_ch, hidden_ch, 4, 2, 1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            self._disc_block(hidden_ch, hidden_ch*2, 4, 2, 1),\n",
        "            self._disc_block(hidden_ch*2, hidden_ch*4, 4, 2, 1),\n",
        "            self._disc_block(hidden_ch*4, hidden_ch*8, 4, 2, 1),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(hidden_ch * 8 * 2 * 2, out_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.disc(x).view(-1, 1)\n",
        "\n",
        "    def _disc_block(self,in_ch, out_ch, kernel, stride, padding):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_ch, out_ch, kernel, stride, padding, bias=False\n",
        "            ),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "gen_noise = lambda number, z_dim: torch.randn(number, z_dim).to(device)"
      ],
      "metadata": {
        "id": "DL6Xbvkuoa-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# img, _ = next(iter(data))\n",
        "# pred = disc(img.to(device))\n",
        "# pred.shape"
      ],
      "metadata": {
        "id": "rambuZpBKcom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen = Generator().to(device)\n",
        "gen.apply(weights_init)\n",
        "gen_opt = torch.optim.Adam(gen.parameters(), lr=LR, betas=(0.5, 0.999))\n",
        "# I we need to change learning rate during training we can use lr_scheduler function in torch.optim\n",
        "gen_exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(gen_opt, step_size=2, gamma=0.9)\n",
        "\n",
        "disc = Discriminator().to(device)\n",
        "disc.apply(weights_init)\n",
        "disc_opt = torch.optim.Adam(disc.parameters(), lr=LR, betas=(0.5, 0.999))\n",
        "disc_exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(disc_opt, step_size=2, gamma=0.9)"
      ],
      "metadata": {
        "id": "mTqCxpgvod9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the data\n",
        "x, y = next(iter(data))\n",
        "print(\"Shape of dataset images: \", x.shape)\n",
        "print(\"label of images\", y[:16])\n",
        "\n",
        "noise = gen_noise(BS, Z_DIM)\n",
        "fake = gen(noise)\n",
        "show(x, ch=C, size=(H, W))\n",
        "show(fake, ch=C, size=(H, W))"
      ],
      "metadata": {
        "id": "239dzlMXoeaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This the the most important part of the training\n",
        "def gen_loss_func(gen_net, disc_net, loss_func, num, z_dim):\n",
        "    noise = gen_noise(num, z_dim)\n",
        "    fake = gen_net(noise)\n",
        "    pred = disc_net(fake)\n",
        "    return loss_func(pred, torch.ones_like(pred))\n",
        "\n",
        "\n",
        "def disc_loss_func(gen_net, disc_net, loss_func, image, num, z_dim):\n",
        "    noise = gen_noise(num, z_dim)\n",
        "    fake = gen_net(noise)\n",
        "    fake_pred = disc_net(fake.detach())  # detach() the generator output so it won't participate in gen_net learning\n",
        "    real_pred = disc_net(image)\n",
        "\n",
        "    loss_real = loss_func(real_pred, torch.ones_like(real_pred))\n",
        "    loss_fake = loss_func(fake_pred, torch.zeros_like(fake_pred))\n",
        "\n",
        "    return (loss_real + loss_fake) / 2"
      ],
      "metadata": {
        "id": "BBz2uMseojP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "!rm -r /content/runs\n",
        "writer = SummaryWriter(\"/content/runs\")\n",
        "writer_fake = SummaryWriter(\"/content/runs/fake\")\n",
        "writer_real = SummaryWriter(\"/content/runs/real\")"
      ],
      "metadata": {
        "id": "8Cz-MdF2LLYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=runs"
      ],
      "metadata": {
        "id": "Uc4rzwuaojkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r $PATH\n",
        "PATH = \"/content/model/\"\n",
        "!mkdir $PATH"
      ],
      "metadata": {
        "id": "nmj25OAaNEFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "step = 0\n",
        "for epoch in range(EPOCH):\n",
        "    discLoss, genLoss = 0, 0\n",
        "    print(f\"\\nEpoch: {epoch + 1}\")\n",
        "\n",
        "    for batch, (real, _) in enumerate(tqdm(data)):\n",
        "        real = real.to(device)\n",
        "        disc_loss = disc_loss_func(gen, disc, loss_func, real, BS, Z_DIM)\n",
        "        disc_opt.zero_grad()\n",
        "        disc_loss.backward(retain_graph=True) # If False, the graph used to compute the grad will be freed, Actually It isnt necessary\n",
        "        disc_opt.step()\n",
        "\n",
        "        gen_loss = gen_loss_func(gen, disc, loss_func, BS, Z_DIM)\n",
        "        gen_opt.zero_grad()\n",
        "        gen_loss.backward(retain_graph=True)\n",
        "        gen_opt.step()\n",
        "\n",
        "        discLoss += disc_loss /len(data)\n",
        "        genLoss += gen_loss /len(data)\n",
        "        if batch % 150 == 0 and batch != 0:\n",
        "            # print(f'  batch: {batch} -- {batch*32} of {len(data.dataset)} sample')\n",
        "            with torch.no_grad():\n",
        "                step += 1\n",
        "                fake = gen(gen_noise(BS, Z_DIM)).view(-1, C, H, W)\n",
        "                image = real.view(-1, C, H, W)\n",
        "                real_grid = make_grid(image[:32], normalize=True)\n",
        "                fake_grid = make_grid(fake[:32], normalize=True)\n",
        "\n",
        "                writer_fake.add_image(\n",
        "                    \"MNIST fake image\", fake_grid, global_step=step\n",
        "                )\n",
        "                writer_real.add_image(\n",
        "                    \"MNIST real image\", real_grid, global_step=step\n",
        "                )\n",
        "\n",
        "\n",
        "    print(f'  Discriminator Loss: {discLoss:.4f} -- Generator Loss: {genLoss:.4f}')\n",
        "    gen_exp_lr_scheduler.step()\n",
        "    disc_exp_lr_scheduler.step()\n",
        "    #Save model\n",
        "    torch.save(gen.state_dict(), f\"{PATH}Gen_{epoch+1}\")\n",
        "    torch.save(disc.state_dict(), f\"{PATH}Disc_{epoch+1}\")\n",
        "    #Tensorboard\n",
        "    writer.add_scalar(\"Loss/Disc\", discLoss, epoch)\n",
        "    writer.add_scalar(\"Loss/Gen\", genLoss, epoch)\n",
        "\n",
        "    writer.add_scalar(\"Loss/Disc\", discLoss, epoch)\n",
        "    writer.add_scalar(\"Loss/Gen\", genLoss, epoch)\n",
        "    if (epoch + 1) % 2 == 0 and epoch > 0:\n",
        "        print(f\"  >>> Discriminator Learning Rate: {disc_opt.param_groups[0]['lr']}\")\n",
        "        print(f\"  >>> Generator Learning Rate: {gen_opt.param_groups[0]['lr']}\")"
      ],
      "metadata": {
        "id": "uZDriRqdN3QS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated = gen(gen_noise(BS, Z_DIM)).view(-1, C, H, W)\n",
        "show(generated)"
      ],
      "metadata": {
        "id": "s1aMjXNSQ_gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VDoXUs7xRaPm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}