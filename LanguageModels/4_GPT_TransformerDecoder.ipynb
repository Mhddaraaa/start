{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Cdy1Whdwz8pb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from tqdm.auto import tqdm\n",
        "import random\n",
        "from collections import Counter\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keymoIMu0Bb0",
        "outputId": "efe65d26-e171-4fe2-fb59-bca6e2d6ffe6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-05-08 21:32:56--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-05-08 21:32:56 (28.4 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "c4bzYxpN0Dlf"
      },
      "outputs": [],
      "source": [
        "with open('/content/input.txt', mode='r', encoding='utf-8') as f:\n",
        "    text = f.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNeJbXp70N_P",
        "outputId": "d4dad302-0753-4ed2-9b8e-a6cde40cbb7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of data:  1115394\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n"
          ]
        }
      ],
      "source": [
        "print('Length of data: ', len(text))\n",
        "print(text[:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcCHNFTq92qv"
      },
      "source": [
        "## **Tokenizer**\n",
        "\n",
        "**Byte Pair Encoding (BPE):** Iteratively merges the most frequent adjacent symbol pairs to reduce vocabulary size while preserving meaning.\n",
        "- This is an unsupervised, data-driven tokenization algorithm often used for compressing and preprocessing input in NLP tasks.\n",
        "\n",
        "**Note:** In it's orginal form, first we should convert all characters to their unicode format. After this we must create new index for each new pairs. Nonetheless, in this implementation I just used the orginal characters and split them using regular expresion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bTyPE669rT-"
      },
      "outputs": [],
      "source": [
        "def merge(words, pair):\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        pairs = [[word[i] + ' ' + word[i+1]] for i in range(len(word) - 1)]\n",
        "        if pair in [''.join(pair) for pair in pairs]:\n",
        "            item = ' '.join(word)\n",
        "            item = item.replace(' '.join(pair.split()), ''.join(pair.split()))\n",
        "            new_words.append(item.split())\n",
        "        else:\n",
        "            new_words.append(word)\n",
        "\n",
        "    return new_words\n",
        "\n",
        "def PBE(text, num_iteration=1000, freq_limit=5, pattern=r\"\\s*\\S+\"):\n",
        "    # Tokenize input text into list of character lists per word\n",
        "    words = [[c for c in item] for item in re.findall(pattern, text)]\n",
        "\n",
        "    pbar = tqdm(range(num_iteration))  # Show progress bar\n",
        "\n",
        "    for _ in pbar:\n",
        "        pairs = []\n",
        "        for item in words:\n",
        "            # Collect all adjacent character pairs from words\n",
        "            pairs += [item[i] + ' ' + item[i+1] for i in range(len(item) - 1)]\n",
        "\n",
        "        # Find most common pair\n",
        "        max = Counter(pairs).most_common(1)[0]\n",
        "\n",
        "        if max[1] > freq_limit:\n",
        "            pair = max[0]\n",
        "            words = merge(words, pair)  # Merge the pair in all words\n",
        "        else:\n",
        "            break  # Stop if no pair is frequent enough\n",
        "\n",
        "        pbar.set_description(f\"Max frequency: {max[1]}, \")\n",
        "\n",
        "    # Flatten the list of words into a single list of subwords/tokens\n",
        "    return [w for word in words for w in word]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "STGE6_Im0VsI"
      },
      "outputs": [],
      "source": [
        "#tokens = PBE(text, num_iteration=4000)\n",
        "\n",
        "# As I train the tokenizer in the past, I just use it\n",
        "!cp \"/content/drive/MyDrive/LLM/TinyShakesCustomTokens4000.npy\" /content/\n",
        "tokens = np.load('/content/TinyShakesCustomTokens4000.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfXaKfg40Voo",
        "outputId": "b43c8fef-882a-45ba-dd66-e2774100a003"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "q was not in the tokens, adding...\n"
          ]
        }
      ],
      "source": [
        "chars = sorted(list(set(tokens)))\n",
        "\n",
        "for item in sorted(list(set(text))):\n",
        "    if item not in chars:\n",
        "        print(item, \"was not in the tokens, adding...\")\n",
        "        chars.append(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wL1Eec1R0Okb"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE = len(chars)\n",
        "T = 256 # length of text sequence\n",
        "BATCH_SIZE = 64\n",
        "LR = 2e-3\n",
        "EPOCHS = 2000\n",
        "EVAL_INTERVAL = 100\n",
        "EVAL_ITER = 5\n",
        "N_EMBD = 192\n",
        "N_HEAD = 8\n",
        "NUM_BLOCK = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LG9WH45c0sLQ"
      },
      "outputs": [],
      "source": [
        "stoi = {ch:i for i, ch in enumerate(chars)} # String to int\n",
        "itos = {i:ch for i, ch in enumerate(chars)} # Int to string\n",
        "\n",
        "encode = lambda s: [stoi[item] for item in s]\n",
        "decode = lambda i:  ''.join(itos[c] for c in i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG8BhvSW0slS",
        "outputId": "075a8009-cf7d-4313-c4b8-4ad0a74bcd5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available device is:  cuda\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(torch.Size([1115394]), torch.int64)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set a random seed for reproducibility of results\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# Choose 'cuda' if a GPU is available, otherwise fall back to CPU\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Available device is: ', device)\n",
        "\n",
        "# Convert the encoded text into a PyTorch tensor, store it on the selected device\n",
        "data = torch.tensor(encode(text), dtype=torch.long, device=device)\n",
        "\n",
        "# Display the shape and data type of the tensor\n",
        "data.shape, data.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoI4_BbP0uJD",
        "outputId": "c9112090-6cd5-45ff-8abc-1b25d5be674a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1003854, 111540)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Split the data into 90% training and 10% testing\n",
        "split = int(0.9 * len(data))\n",
        "train_data = data[:split]\n",
        "test_data = data[split:]\n",
        "\n",
        "# Show the lengths of the training and testing sets\n",
        "len(train_data), len(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZbzkveJN0v4f"
      },
      "outputs": [],
      "source": [
        "# Function to generate a batch of input (x) and target (y) sequences from the dataset\n",
        "def get_batch(data_set, device, T=T):\n",
        "    # Randomly select starting indices for BATCH_SIZE number of sequences\n",
        "    # Ensures sequences of length T can be formed without going out of bounds\n",
        "    idx = torch.randint(len(data_set) - T, (BATCH_SIZE,))\n",
        "\n",
        "    # Stack BATCH_SIZE input sequences of length T starting from the random indices\n",
        "    x = torch.stack([data_set[i: i + T] for i in idx]).to(device)\n",
        "\n",
        "    # Stack BATCH_SIZE target sequences by shifting each input sequence by one token\n",
        "    y = torch.stack([data_set[i + 1: i + T + 1] for i in idx]).to(device)\n",
        "\n",
        "    # Return a batch of input and corresponding target sequences\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RF_FK6Nk2rr4"
      },
      "source": [
        "## **Transfomer decoder architecture impelemtetion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xvkle8-32rj3"
      },
      "source": [
        "### **1. Single Attention Head (Head)**\n",
        "\n",
        "First is implementing **scaled dot-product** attention with **causal masking** for autoregressive token prediction. It models how each token attends to previous tokens in the sequence.\n",
        "\n",
        "Given a sequence of token embeddings $X \\in \\mathbb{R}^{B \\times T \\times C}$, we compute attention weights:\n",
        "<br>\n",
        "\n",
        "$$\n",
        "\\large \\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^\\top}{\\sqrt{d_k}} + \\text{mask} \\right)V\n",
        "$$\n",
        "\n",
        "> Query: $Q = XW^Q$ <br>\n",
        "Key: $K = XW^K$ <br>\n",
        "Value: $V = XW^V$ <br>\n",
        "$d_k$: Dimension of keys (i.e., head size) <br>\n",
        "*mask:* Causal (lower triangular) mask ensures no future tokens are attended."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCwuwcmc2Fq7"
      },
      "outputs": [],
      "source": [
        "class Head(nn.Module):\n",
        "    def __init__(self, n_embd=N_EMBD, h_s=HEAD_SIZE):\n",
        "        super().__init__()\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "        # Linear projections for Q, K, V (no bias for simplicity)\n",
        "        self.query = nn.Linear(n_embd, h_s, bias=False)\n",
        "        self.key = nn.Linear(n_embd, h_s, bias=False)\n",
        "        self.value = nn.Linear(n_embd, h_s, bias=False)\n",
        "\n",
        "        self.drop = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape  # Batch, Time, Embedding size\n",
        "        q = self.query(x)  # (B, T, h_s)\n",
        "        k = self.key(x)\n",
        "        v = self.value(x)\n",
        "\n",
        "        # Scaled dot-product attention\n",
        "        wei = (q @ k.transpose(-1, -2)) * (C ** -0.5)\n",
        "\n",
        "        # Apply causal mask to prevent attending to future positions\n",
        "        tril = torch.tril(torch.ones(T, T)).to(self.device)\n",
        "        wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "\n",
        "        # Apply softmax + dropout\n",
        "        wei = self.drop(F.softmax(wei, dim=-1))  # (B, T, T)\n",
        "\n",
        "        # Weighted sum of value vectors\n",
        "        return wei @ v  # (B, T, h_s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dw06ihHA4K8Y"
      },
      "source": [
        "### **2. Multi-head Attention (MultiHead)**\n",
        "Combines multiple attention heads in parallel to allow the model to jointly attend to information from different representation subspaces at different position, which enables richer representations than a single head.\n",
        "\n",
        "If we use $h$ heads, each head computes its own attention:\n",
        "<br>\n",
        "\n",
        "$$\n",
        "\\large \\text{head}_i = \\text{Attention}(Q_i, K_i, V_i)\n",
        "$$\n",
        "\n",
        "The outputs are concatenated and projected:\n",
        "<br>\n",
        "\n",
        "$$\n",
        "\\large \\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1, \\ldots, \\text{head}_h)W^O\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EopFvG8I2FbC"
      },
      "outputs": [],
      "source": [
        "class MultiHead(nn.Module):\n",
        "    def __init__(self, n_embd=N_EMBD, n_h=N_HEAD):\n",
        "        super().__init__()\n",
        "        # Create n_h attention heads\n",
        "        self.multi_head = nn.ModuleList([\n",
        "            Head(n_embd, n_embd // n_h) for _ in range(n_h)\n",
        "        ])\n",
        "\n",
        "        # Output projection layer to mix heads\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.drop = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply all attention heads and concatenate their outputs\n",
        "        x = torch.cat([head(x) for head in self.multi_head], dim=-1)\n",
        "        return self.drop(self.proj(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FULwZ0H40kC"
      },
      "source": [
        "### **3. Feedforward**\n",
        "\n",
        "Processes each position independently to apply a non-linear transformation and deepen the model. we can say we this approach tokens will speak together to find out each one carry what kind of information.\n",
        "\n",
        "Each position of the sequence (vector) goes through:\n",
        "<br>\n",
        "\n",
        "$$\n",
        "\\large \\text{FFN}(x) = W_2 \\cdot \\text{GELU}(W_1 x + b_1) + b_2\n",
        "$$\n",
        "\n",
        "> Usually $W_1 \\in \\mathbb{R}^{d_{\\text{model}} \\times 4d_{\\text{model}}}$ <br>\n",
        "This makes the model more expressive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4fWEdNF2LBm"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, in_channel):\n",
        "        super().__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Linear(in_channel, in_channel * 4),  # Expand\n",
        "            nn.GELU(),\n",
        "            nn.Linear(in_channel * 4, in_channel),  # Reduce\n",
        "            nn.Dropout(0.2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsxbBQIX56zh"
      },
      "source": [
        "### **4. Transformer Block**\n",
        "\n",
        "Each block applies:\n",
        "\n",
        "1.\tMulti-head attention with residual:\n",
        "$$\n",
        "\\large x’ = x + \\text{MultiHead}(\\text{LayerNorm}(x))\n",
        "$$\n",
        "2.\tFeedforward with residual:\n",
        "$$\n",
        "\\large x’’ = x’ + \\text{FFN}(\\text{LayerNorm}(x’))\n",
        "$$\n",
        "\n",
        "These residual connections help with gradient flow in deep networks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVZu2auH2K_B"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, n_embd=N_EMBD, n_h=N_HEAD):\n",
        "        super().__init__()\n",
        "        self.attention_heads = MultiHead(n_embd, n_h)\n",
        "        self.layer_norm1 = nn.LayerNorm(n_embd)\n",
        "        self.feed_forward = FeedForward(n_embd)\n",
        "        self.layer_norm2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Residual + LayerNorm + Attention\n",
        "        x = x + self.attention_heads(self.layer_norm1(x))\n",
        "        # Residual + LayerNorm + FFN\n",
        "        x = x + self.feed_forward(self.layer_norm2(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKQIqi_Q6wfk"
      },
      "source": [
        "### **5. Bigram Language Model (Full Transformer)**\n",
        "\n",
        "This is the complete causal transformer, trained to predict the next token in a sequence.\n",
        "\n",
        "- Input Representation:\n",
        "\n",
        "$$\n",
        "\\large x = E_{\\text{token}} + E_{\\text{pos}}\n",
        "$$\n",
        "\n",
        "> Token embedding: $E_{\\text{token}}$ <br>\n",
        "Positional embedding: $E_{\\text{pos}}$\n",
        "\n",
        "- Stack of Transformer Blocks: Refines representation\n",
        "- Output Head:\n",
        "\n",
        "$$\n",
        "\\large \\text{logits} = xW^{\\top}_{\\text{vocab}}\n",
        "$$\n",
        "\n",
        "- Loss Function: Uses cross-entropy:\n",
        "\n",
        "$$\n",
        "\\large \\mathcal{L} = -\\sum_{i=1}^{T} \\log p(y_i \\mid x_{<i})\n",
        "$$\n",
        "\n",
        "> Generation: Sample from the output distribution to generate one token at a time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEteR3e32FY8"
      },
      "outputs": [],
      "source": [
        "class Bigram(nn.Module):\n",
        "    def __init__(self, vocab_size=VOCAB_SIZE, char_length=T, n_embd=N_EMBD,\n",
        "                 n_h=N_HEAD, num_block=8):\n",
        "        super().__init__()\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        self.char_length = char_length\n",
        "\n",
        "        # Token and positional embeddings\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.pos_embedding_table = nn.Embedding(char_length, n_embd)\n",
        "\n",
        "        # Stack of transformer blocks\n",
        "        self.transformerblock = nn.ModuleList([\n",
        "            TransformerBlock(n_embd, n_h) for _ in range(num_block)\n",
        "        ])\n",
        "\n",
        "        self.norm_layer = nn.LayerNorm(n_embd)\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)  # Final classifier\n",
        "        self.to(self.device)\n",
        "\n",
        "    def forward(self, input, target=None):\n",
        "        B, T = input.shape\n",
        "\n",
        "        # Lookup embeddings\n",
        "        token_embd = self.token_embedding_table(input)       # (B, T, N_EMBD)\n",
        "        positional_embd = self.pos_embedding_table(torch.arange(T, device=self.device))  # (T, N_EMBD)\n",
        "\n",
        "        x = token_embd + positional_embd  # (B, T, N_EMBD)\n",
        "\n",
        "        # Apply transformer blocks\n",
        "        for layer in self.transformerblock:\n",
        "            x = layer(x)\n",
        "\n",
        "        # Final normalization + logits\n",
        "        x = self.norm_layer(x)\n",
        "        logits = self.lm_head(x)  # (B, T, VOCAB_SIZE)\n",
        "\n",
        "        # If no target, return logits for inference\n",
        "        if target is None:\n",
        "            return logits, None\n",
        "\n",
        "        # Flatten for loss computation\n",
        "        logits = logits.view(B * T, -1)\n",
        "        target = target.view(-1)\n",
        "        loss = F.cross_entropy(logits, target)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate_token(self, input, max_token):\n",
        "        # Generate max_token number of tokens\n",
        "        for _ in range(max_token):\n",
        "            logits, _ = self.forward(input[:, -self.char_length:])\n",
        "\n",
        "            # Get next token probabilities from the last position\n",
        "            probs = F.softmax(logits[:, -1, :], dim=-1)  # (B, VOCAB_SIZE)\n",
        "\n",
        "            # Sample from the distribution\n",
        "            next_char = torch.multinomial(probs, 1)  # (B, 1)\n",
        "\n",
        "            # Append new token to input\n",
        "            input = torch.cat([input, next_char], dim=1)  # (B, T+1)\n",
        "\n",
        "        return decode(input[0].detach().cpu().tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nSbgJ1ui0_jm"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()  # Disables gradient calculation to save memory and improve inference speed (no backprop during evaluation)\n",
        "def calc_loss(data, model, iter_num, device):\n",
        "    # Initialize a tensor to store loss values for each iteration\n",
        "    losses = torch.zeros(iter_num)\n",
        "\n",
        "    # Set the model to evaluation mode (disables dropout, layer norm uses running stats, etc.)\n",
        "    model.eval()\n",
        "\n",
        "    # Run the evaluation loop for the given number of iterations\n",
        "    for i in range(iter_num):\n",
        "        # Sample a batch of input and target sequences\n",
        "        x, y = get_batch(data, device)\n",
        "\n",
        "        # Get the model output and compute the loss (no gradients)\n",
        "        out, loss = model(x, y)\n",
        "\n",
        "        # Store the scalar loss value\n",
        "        losses[i] = loss.item()\n",
        "\n",
        "    # Return the model to training mode (enables dropout, etc.)\n",
        "    model.train()\n",
        "\n",
        "    # Return the mean loss across all iterations as a float\n",
        "    return losses.mean().item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "G2igtkGc1BOS"
      },
      "outputs": [],
      "source": [
        "def train_mode(model, optim, opt_schedul, epochs, eval_interval,\n",
        "               eval_iter, device, model_path=None):\n",
        "\n",
        "    # === Load from checkpoint if available ===\n",
        "    if model_path:\n",
        "        checkpoint = torch.load(model_path, weights_only=False)\n",
        "        model = checkpoint['model']                  # Load the saved model\n",
        "        optim = checkpoint['optimizer']              # Load the saved optimizer\n",
        "        opt_schedul = checkpoint['lr_sched']         # Load the learning rate scheduler\n",
        "\n",
        "    train_losses = []         # List to store training loss values\n",
        "    boundry = float('inf')    # Initialize best validation loss to infinity\n",
        "\n",
        "    pbar = tqdm(range(epochs))  # Progress bar for training\n",
        "    for epoch in pbar:\n",
        "        # === Get a batch of training data ===\n",
        "        x, y = get_batch(train_data, device)\n",
        "\n",
        "        # === Forward pass ===\n",
        "        out, train_loss = model(x, y)\n",
        "        train_losses.append(train_loss)  # Record the training loss\n",
        "\n",
        "        # === Backward pass and optimization ===\n",
        "        optim.zero_grad(set_to_none=True)  # Clear previous gradients\n",
        "        train_loss.backward()              # Compute gradients via backpropagation\n",
        "        optim.step()                       # Update model weights\n",
        "        opt_schedul.step()                 # Update learning rate via scheduler\n",
        "\n",
        "        # === Periodically evaluate model ===\n",
        "        if (epoch + 1) % eval_interval == 0:\n",
        "            loss = []\n",
        "            for split in [train_data, test_data]:\n",
        "                loss.append(calc_loss(split, model, eval_iter, device))  # Compute average loss\n",
        "\n",
        "            # Show loss and learning rate\n",
        "            pbar.set_description(\n",
        "                f\"Train loss: {loss[0]:.4f} | Val loss: {loss[1]:.4f} |\"\n",
        "                f\" α Neural network: {round(optim.param_groups[0]['lr'], 6)}\"\n",
        "            )\n",
        "\n",
        "            # === Save model checkpoint if validation loss improves ===\n",
        "            if loss[1] < boundry:\n",
        "                boundry = loss[1]\n",
        "                checkpoint = {\n",
        "                    'model': model,\n",
        "                    'optimizer': optim,\n",
        "                    'lr_sched': opt_schedul\n",
        "                }\n",
        "                torch.save(checkpoint, 'checkpoint.pth')  # Save checkpoint\n",
        "\n",
        "    return train_losses  # Return list of training losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wD58IHDr1DE9"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE = len(chars)\n",
        "T = 256 # length of text sequence\n",
        "BATCH_SIZE = 64\n",
        "LR = 2e-3\n",
        "EPOCHS = 2000\n",
        "EVAL_INTERVAL = 100\n",
        "EVAL_ITER = 5\n",
        "N_EMBD = 192\n",
        "N_HEAD = 8\n",
        "NUM_BLOCK = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DvR_FpvV1IA8"
      },
      "outputs": [],
      "source": [
        "# Instantiate the Transformer-based language model ===\n",
        "model = Bigram(\n",
        "    vocab_size=VOCAB_SIZE,     # Size of vocabulary (number of unique tokens)\n",
        "    char_length=T,             # Maximum context window (sequence length)\n",
        "    n_embd=N_EMBD,             # Embedding dimension (feature size)\n",
        "    n_h=N_HEAD,                # Number of attention heads\n",
        "    num_block=NUM_BLOCK        # Number of transformer blocks (depth)\n",
        ")\n",
        "\n",
        "# Initialize AdamW optimizer ===\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
        "\n",
        "# Learning rate scheduler that decays LR every 100 steps ===\n",
        "opt_schedul = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.99)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "5ec0591de3a7485e8a06930c731824f8",
            "eba1b2ebdc4d4b65904421d6a9b6bd1d",
            "8db3deb19fd94b09a91dc467028575f3",
            "fc927f1d60da44e08ba1c8f44aa7342f",
            "49950f80e892462aae364012f0295441",
            "c5814fdfb24949f3a0cc688f7d59a84c",
            "1a0652e4c0404083a64947cd70e3b531",
            "6c040e708d224127a466bd86aece0ae0",
            "c401e60a3f894611aaf652a1b223c62d",
            "805ca494a99e4f2c98bd66a035976232",
            "8e1fd5dd3e824c978c7c8631f42a6956"
          ]
        },
        "id": "KmaXsYoD1KTZ",
        "outputId": "6f86f0d3-475d-4157-810b-e954f17bc1eb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ec0591de3a7485e8a06930c731824f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_loss = train_mode(model, optimizer, opt_schedul, EPOCHS, EVAL_INTERVAL,\n",
        "                        EVAL_ITER, device = device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "gCbOq9Tu1ORm",
        "outputId": "3b6df2e4-16a2-490d-e43d-7f01c9bede1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Loss is:  1.4962822198867798\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print('Val Loss is: ', calc_loss(test_data, model, 5, device))\n",
        "plt.plot(torch.tensor(train_loss).cpu().numpy())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sa2wB23T8zmc",
        "outputId": "0a282faf-42ab-4c4a-9101-c7230a19a9a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Secure, thou hast done with the honour of the goss\n",
            "stren. How! Montague forgive those this\n",
            "forth, I should ask,\n",
            "any let thee weed, and of Rome, and this wing\n",
            "membring thy happy instructs. But, if we have\n",
            "did so offender; and make ease of love time\n",
            "own full days of letters. But, and the news cape,\n",
            "As each of faults of holy vict:\n",
            "The birthless wheels the was a Crosby, it wass for\n",
            "two sented in his heir, and man hateful is\n",
            "that would have?\n",
            "\n",
            "PAULINA:\n",
            "Indeed;\n",
            "Both and and dear days of saying fineess,\n",
            "To make thee larged-head; no liver from and die:\n",
            "It should be the little lives our head;\n",
            "And made me my pleasure of Rome,\n",
            "'Tis blind to us; Is fall in forfeit\n",
            "With one hundred looks the welewise lie!\n",
            "Ha! wondon he censure, who shoes wanders\n",
            "Made for adversared, for his brother had brought:\n",
            "We have some vantage: who cames\n",
            "Mine own of griefect was done to roan?\n",
            "\n",
            "ANTIGONUS:\n",
            "Ay, by her careless of me, gains-wife,\n",
            "And from flowers and Jerkius, to go:\n",
            "Be rply, my liege,\n",
            "Be in the looking of my brain\n"
          ]
        }
      ],
      "source": [
        "print(model.generate_token(torch.zeros((1, 1), dtype=torch.long, device=device), 1000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "xqhuwysb83Tx"
      },
      "outputs": [],
      "source": [
        "!cp /content/checkpoint.pth /content/drive/MyDrive/LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfVGLkNC9bHB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
