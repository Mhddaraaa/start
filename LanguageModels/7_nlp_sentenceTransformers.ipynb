{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qZKBoWW9_VN"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download en_core_web_lg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VnuL6o7f-r6"
      },
      "outputs": [],
      "source": [
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqHEAkNL84hI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import torch\n",
        "import spacy\n",
        "import transformers\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QAdnMR0-IZ5",
        "outputId": "91afa9ea-bbfc-4190-a966-c655de740739"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jack PERSON\n",
            "Iphone ORG\n",
            "Apple ORG\n"
          ]
        }
      ],
      "source": [
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "sentence = \"Hello dear Jack I want to know did you buy an Iphone, which is an Apple product, or you have you old phone\"\n",
        "doc = nlp(sentence)\n",
        "\n",
        "for token in doc.ents:\n",
        "    print(token.text, token.label_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmAaexIc-uiq"
      },
      "outputs": [],
      "source": [
        "NER = transformers.pipeline('ner', grouped_entities = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krv3cqFSBQJj",
        "outputId": "c4a9af6a-0623-49f7-8b1c-7980c5a73f15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jack :  PER\n",
            "I :  MISC\n",
            "Apple :  ORG\n"
          ]
        }
      ],
      "source": [
        "for item in NER(sentence):\n",
        "    print(item['word'], \": \", item['entity_group'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Pw0eZ9PAanU"
      },
      "source": [
        "## SenteceTransformers\n",
        "\n",
        "Approach | Description | Goal\n",
        "---------|-------------|-----\n",
        "AutoTokenizer + AutoModel <br> → last_hidden_state.mean(dim=1) | You directly use a pretrained Transformer (e.g., BERT, RoBERTa) <br>to produce embeddings by averaging token representations. | Creates contextual embeddings without <br> extra training for sentence-level tasks.\n",
        "SentenceTransformer | A model trained specifically to generate semantically meaningful <br> sentence embeddings using contrastive or triplet objectives. | Creates sentence-level semantic embeddings <br> optimized for similarity, clustering, retrieval.\n",
        "\n",
        "\n",
        "> So if you want to capture semantice of a sentence `sentence_transformers.SentenceTransformer` is far better than using `AutoTokenizer --> AutoModel --> last_headen_state.mean(dim = 1)`\n",
        "\n",
        "<br>\n",
        "\n",
        "> `SentenceTransformer` models: `all-MiniLM-L6-v2`, `all-distilroberta-v1`, etc.\n",
        "\n",
        "<br>\n",
        "\n",
        "Sentence embeddings convert entire sentences or documents into vectors that capture semantic meaning:\n",
        "- Semantic search\n",
        "- Clustering documents\n",
        "- Duplicate detection\n",
        "- Retrieval-augmented generation (RAG)\n",
        "\n",
        "<br>\n",
        "\n",
        "multilingual models:\n",
        "- `paraphrase-multilingual-MiniLM-L12-v2` (lighter)\n",
        "- `paraphrase-multilingual-mpnet-base-v2`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Search models:\n",
        "\n",
        "```py\n",
        "from huggingface_hub import list_models\n",
        "\n",
        "# Find models for specific task\n",
        "models = list_models(\n",
        "    filter=\"text-classification\",  # or \"token-classification\", \"question-answering\"\n",
        "    library=\"transformers\",\n",
        "    limit=10\n",
        ")\n",
        "\n",
        "\n",
        "# Filter by SentenceTransformers library\n",
        "sentence_models = list_models(\n",
        "    filter = \"sentence-similarity\",  # Common task for sentence transformers\n",
        "    # filter=\"sentence-transformers\", # Search by specific architecture \n",
        "    library = \"sentence-transformers\",\n",
        "    limit=10\n",
        ")\n",
        "\n",
        "\n",
        "for model in models:\n",
        "    print(f\"{model.model_id} | Downloads: {model.downloads}\")\n",
        "\n",
        "# Search by architecture\n",
        "bert_models = list_models(filter=\"bert\", library=\"transformers\", limit=5)\n",
        "for model in bert_models:\n",
        "    print(model.model_id)\n",
        "\n",
        "# Search by model name\n",
        "models = list_models(\n",
        "    search=\"bert\",  # Search in model names\n",
        "    library=\"transformers\"\n",
        ")\n",
        "\n",
        "# Filter by tags\n",
        "models = list_models(\n",
        "    filter=(\"text-generation\", \"gpt2\"),\n",
        "    library=\"transformers\"\n",
        ")\n",
        "```\n",
        "\n",
        "- library=\"transformers\"\n",
        "- library=\"sentence-transformers\"\n",
        "- library=\"tokenizers\"\n",
        "- library=\"datasets\"\n",
        "- library=\"diffusers\" \n",
        "- library=\"safetensors\"\n",
        "- library=\"all\"\n",
        "\n",
        "<br>\n",
        "\n",
        "# Most Common Tasks:\n",
        "- filter=\"text-classification\"\n",
        "- filter=\"token-classification\"           # NER\n",
        "- filter=\"text-generation\"\n",
        "- filter=\"question-answering\" \n",
        "- filter=\"sentence-similarity\"\n",
        "- filter=\"fill-mask\"\n",
        "- filter=\"summarization\"\n",
        "- filter=\"translation\"\n",
        "- filter=\"text2text-generation\"\n",
        "- filter=\"image-classification\"\n",
        "- filter=\"automatic-speech-recognition\"\n",
        "- filter=\"audio-classification\"\n",
        "\n",
        "# Less Common Tasks:\n",
        "filter=\"table-question-answering\"\n",
        "filter=\"document-question-answering\"\n",
        "filter=\"visual-question-answering\"\n",
        "filter=\"image-segmentation\"\n",
        "filter=\"object-detection\"\n",
        "filter=\"text-to-speech\"\n",
        "filter=\"text-to-audio\"\n",
        "filter=\"audio-to-audio\"\n",
        "filter=\"zero-shot-classification\"\n",
        "filter=\"zero-shot-image-classification\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvYhLRxF_KeY"
      },
      "outputs": [],
      "source": [
        "model = SentenceTransformer('all-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-3zfMwTC_Uz",
        "outputId": "bd8dd90c-ebf3-471b-aee5-fab458d4af5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5, 384)\n"
          ]
        }
      ],
      "source": [
        "sentences = [\n",
        "    \"I like read book.\",\n",
        "    \"books are amazing, since they improve your knowledge.\",\n",
        "    \"He is a good driver, and know how to repaire his car.\",\n",
        "    \"my brother bought a motorcycle last year, and crash into a bookstore first day\",\n",
        "    \"most of the men love to spend time with their car.\"\n",
        "]\n",
        "\n",
        "embeddings = model.encode(sentences)\n",
        "print(embeddings.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpJpA5FNFh74",
        "outputId": "8f3694c9-fc7c-4773-b0c2-7ffec657fbbc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.6411, 0.1553, 0.2553, 0.1783],\n",
              "        [0.6411, 1.0000, 0.1675, 0.2908, 0.0510],\n",
              "        [0.1553, 0.1675, 1.0000, 0.3187, 0.3545],\n",
              "        [0.2553, 0.2908, 0.3187, 1.0000, 0.2843],\n",
              "        [0.1783, 0.0510, 0.3545, 0.2843, 1.0000]])"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Now I want to check similarity between all sentences\n",
        "model.similarity(embeddings, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_Yxg4trFyjR",
        "outputId": "da00b79f-f579-45f8-c298-f78eb71e3b44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "He is a good driver, and know how to repaire his car. :  0.34426796\n",
            "most of the men love to spend time with their car. :  0.31730774\n"
          ]
        }
      ],
      "source": [
        "# know let's check a sentece similarity with preview sentences\n",
        "sentence = [\"Today is a good day to drive fast\"]\n",
        "sentence_embedding = model.encode(sentence)\n",
        "score = model.similarity(sentence_embedding, embeddings).reshape(-1,).numpy()\n",
        "score_arg = np.argsort(score)[::-1]\n",
        "\n",
        "for idx in score_arg[:2]:\n",
        "    print(sentences[idx], \": \", score[idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LF0-0bijJl5V"
      },
      "source": [
        "## FAISS\n",
        "\n",
        "Facebook AI Similarity Search allows fast nearest neighbor search on millions of embeddings.\n",
        "<br>\n",
        "\n",
        "Use cases:\n",
        "- Recommendation systems\n",
        "- Semantic search\n",
        "- Vector databases (e.g., Pinecone, Chroma, Weaviate)\n",
        "\n",
        "<br>\n",
        "\n",
        "> [Reference](https://www.pinecone.io/learn/series/faiss/faiss-tutorial/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRSgZkE2TpjC"
      },
      "source": [
        "### IndexFlatL2\n",
        "It measures the L2 (or Euclidean) distance between all given points between our query vector, and the vectors loaded into the index.\n",
        "> It’s simple, very accurate, but not too fast.\n",
        "\n",
        "<br>\n",
        "\n",
        "<img width = 400 src = \"https://www.pinecone.io/_next/image/?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fvr8gru94%2Fproduction%2Fea951a4be3acf9d379cc6f922be1468b37b7f9e5-1280x720.png&w=3840&q=75\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XlPh735JQC4",
        "outputId": "d04e25f8-80a4-4eb0-85e4-283d5932eaa6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding shape:  (5, 384)\n",
            "Index is trained: True\n",
            "total number of sentences 5\n"
          ]
        }
      ],
      "source": [
        "import faiss\n",
        "\n",
        "\n",
        "checkpoint1 = 'all-MiniLM-L6-v2'\n",
        "checkpoint2 = 'bert-base-nli-mean-tokens'\n",
        "\n",
        "model = SentenceTransformer(checkpoint1)\n",
        "\n",
        "sentences = [\n",
        "    \"I like read book.\",\n",
        "    \"books are amazing, since they improve your knowledge.\",\n",
        "    \"He is a good driver, and know how to repaire his car.\",\n",
        "    \"my brother bought a motorcycle last year, and crash into a bookstore first day\",\n",
        "    \"most of the men love to spend time with their car.\"\n",
        "]\n",
        "\n",
        "# create sentence embeddings\n",
        "sentence_embeddings = model.encode(sentences)\n",
        "\n",
        "# extract the embedding size\n",
        "print(\"Embedding shape: \", sentence_embeddings.shape)\n",
        "d = sentence_embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(d)\n",
        "\n",
        "# Check whether an index is trained\n",
        "print(f\"Index is trained: {index.is_trained}\")\n",
        "\n",
        "# Load embeddings\n",
        "index.add(sentence_embeddings)\n",
        "print(\"total number of sentences\",index.ntotal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZj9HhKwJ7dd",
        "outputId": "441862ed-4f3c-436a-ed54-f9fa2be967d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[2 3 4 0]]\n"
          ]
        }
      ],
      "source": [
        "k = 4 # number of nearest neigbours\n",
        "querry = model.encode([\"Someone deriving fast and crash his car into a wall\"]) # query\n",
        "\n",
        "\n",
        "D, I = index.search(querry, k)  # search, I are indices\n",
        "print(I)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJzU0jZrRidu",
        "outputId": "47039e49-d1c0-4253-e711-a9536fb5e037"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "He is a good driver, and know how to repaire his car.\n",
            "books are amazing, since they improve your knowledge.\n"
          ]
        }
      ],
      "source": [
        "score_arg = np.argsort(I[0])[::-1]\n",
        "\n",
        "for idx in score_arg[:2]:\n",
        "    print(sentences[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hn0_-B2aRibY"
      },
      "outputs": [],
      "source": [
        "# extract the numerical vectors from Faiss.\n",
        "\n",
        "# d: embedding size\n",
        "# k: Number of neighbours\n",
        "vecs = np.zeros((k, d))\n",
        "# then iterate through each ID from I and add the reconstructed vector to our zero-array\n",
        "for i, val in enumerate(I[0].tolist()):\n",
        "    vecs[i, :] = index.reconstruct(val)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jzsdy1gCTtWV"
      },
      "source": [
        "### Partitioning The Index\n",
        "\n",
        "Using this method, we would take a query vector xq, identify the cell it belongs to, and then use `IndexFlatL2`\n",
        "\n",
        "> now we have to train our index on our data — which we must do before adding any data to the index.\n",
        "\n",
        "<br>\n",
        "\n",
        "<img width=400 src=\"https://www.pinecone.io/_next/image/?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fvr8gru94%2Fproduction%2Fca1ed9b80fd0788cee513ef75c1b8bd8daad8571-1400x748.png&w=3840&q=75\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_k_jQpURiZH",
        "outputId": "392a4909-1ee2-428b-f1b0-59bfcff7fa31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index is trained: False\n",
            "Index is trained: True\n",
            "total number of sentences 5\n",
            "\n",
            "He is a good driver, and know how to repaire his car.\n",
            "books are amazing, since they improve your knowledge.\n"
          ]
        }
      ],
      "source": [
        "nlist = 2  # Number of partitions (Voronoi cells)\n",
        "quantizer = faiss.IndexFlatL2(d) # using the L2 index as a quantizer step\n",
        "index = faiss.IndexIVFFlat(quantizer, d, nlist)\n",
        "\n",
        "print(f\"Index is trained: {index.is_trained}\")\n",
        "index.train(sentence_embeddings)\n",
        "print(f\"Index is trained: {index.is_trained}\")\n",
        "\n",
        "index.add(sentence_embeddings)\n",
        "print(\"total number of sentences\",index.ntotal)  # number of embeddings indexed\n",
        "print()\n",
        "\n",
        "\n",
        "# Number of  nearby cells to search. increase accuracy\n",
        "index.nprobe = 10\n",
        "D, I = index.search(querry, k)  # search\n",
        "\n",
        "\n",
        "score_arg = np.argsort(I[0])[::-1]\n",
        "\n",
        "for idx in score_arg[:2]:\n",
        "    print(sentences[idx])\n",
        "\n",
        "index.make_direct_map()\n",
        "\n",
        "# First create direct mappings,\n",
        "#   since there is no direct mapping between the original vectors and their index position\n",
        "vecs = np.zeros((k, d))\n",
        "for i, val in enumerate(I[0].tolist()):\n",
        "    vecs[i, :] = index.reconstruct(val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n__MaPGcX3Xh"
      },
      "source": [
        "### Quantization\n",
        "\n",
        "```python\n",
        "m = 8  # number of centroid IDs in final compressed vectors\n",
        "bits = 8 # number of bits in each centroid\n",
        "\n",
        "quantizer = faiss.IndexFlatL2(d)  # we keep the same L2 distance flat index\n",
        "index = faiss.IndexIVFPQ(quantizer, d, nlist, m, bits)\n",
        "\n",
        "index.train(sentence_embeddings)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yr8RllsJ9Pd"
      },
      "source": [
        "## Similarity search project\n",
        "\n",
        "extract reviews from [kaggle dataset](https://www.kaggle.com/datasets/arhamrumi/amazon-product-reviews)\n",
        "\n",
        "```sh\n",
        "kaggle datasets download arhamrumi/amazon-product-reviews\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yPd5rxmJ7W_"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp ./kaggle.json  ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download arhamrumi/amazon-product-reviews\n",
        "!7z x /content/amazon-product-reviews.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "pOzkNH3LcITP",
        "outputId": "92e36be1-0e0e-42bf-b829-56a438efc558"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-de47f1f7-2385-4982-b9e0-85585daab307\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de47f1f7-2385-4982-b9e0-85585daab307')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-de47f1f7-2385-4982-b9e0-85585daab307 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-de47f1f7-2385-4982-b9e0-85585daab307');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6f49ce12-0a0e-4955-b024-3a182f81cb9c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6f49ce12-0a0e-4955-b024-3a182f81cb9c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6f49ce12-0a0e-4955-b024-3a182f81cb9c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   Id   ProductId          UserId                      ProfileName  \\\n",
              "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
              "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
              "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
              "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
              "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
              "\n",
              "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
              "0                     1                       1      5  1303862400   \n",
              "1                     0                       0      1  1346976000   \n",
              "2                     1                       1      4  1219017600   \n",
              "3                     3                       3      2  1307923200   \n",
              "4                     0                       0      5  1350777600   \n",
              "\n",
              "                 Summary                                               Text  \n",
              "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
              "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
              "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
              "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
              "4            Great taffy  Great taffy at a great price.  There was a wid...  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.set_option(\"display.max_columns\", None)\n",
        "df = pd.read_csv(\"/content/Reviews.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiI5gxT0daWl",
        "outputId": "5e7f5684-d72d-46b0-cc74-89281bca3ffb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(568454,)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviews = df['Text'].values\n",
        "reviews.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82,
          "referenced_widgets": [
            "5a5ec958ae514f7f95d061d5e3f7aa52",
            "e093b3eb4d0c43b68ba6b05ab639c11a",
            "13775159a92f4245a66ac02c4c3165b6",
            "b761bcd896a14ae5a52c2e597861539a",
            "70f5436ed67146da974bb9dd4f8a927c",
            "b51f5a170dd649f4a58ef8e3501bbb26",
            "bc961b149e5e4d47a8353e7163a578c6",
            "486db7a404624f24bf21d5c0c5b68b98",
            "3cd07ba3cad743b29a5243b429e5891a",
            "f0e5755cf3dd401bbe2023373cd8d0a1",
            "123b3dfd2269431e8d75a2f975f93d65"
          ]
        },
        "id": "KaF7I0gzdpjf",
        "outputId": "4d987c02-c642-4d7a-a1fc-5cce083ca393"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available devie:  cuda\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a5ec958ae514f7f95d061d5e3f7aa52",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/313 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding shape: (10000, 384)\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Available devie: \", device)\n",
        "checkpoint = \"all-MiniLM-L6-v2\"\n",
        "model = SentenceTransformer(checkpoint).to(device)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    embedding = model.encode(reviews[:10000], batch_size = 32, show_progress_bar = True) # convert_to_numpy=True     For FAISS compatibility\n",
        "print(f\"Embedding shape: {embedding.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiNouFxyfK15"
      },
      "outputs": [],
      "source": [
        "querry = model.encode([\"I love this device, it has a greate battery, nice design, and powerful cpu.\"])\n",
        "similarities = model.similarity(querry, embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8wJCshdfKzh",
        "outputId": "2ecf5a83-f890-4a84-a1f1-e0e12407415d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['The individual Pocky sticks are not separately packaged and melt and stick together while being shipped.'\n",
            " 'I bought these and yes they do come in plastic bags with a label on each but also included was a five sided box that you can fold together that has a picture of each flavor, one on each side. It makes a cute little colorful box, nice to give as a gift if you put it together.'\n",
            " 'These Piquillos are packaged in a thin plastic package, though I thought from the picture that they were packed in a roll-top tin (like sardines are packed in).The peppers that survived the shipping were very good, lightly roasted and with good tangy flavor. However, one of the packages was damaged in shipment and leaked red oil all over the rest of the packs, making a huge mess.'\n",
            " ...\n",
            " \"Great audio, until a few months in it just decides to stop working. Common problem: google it and you'll see. Cheapest construction of any product every designed in the entire world. Feels like a fast food toy.<br /><br />I do not recommend this product. Piece o' garbage.\"\n",
            " 'Just excellent product !!!!. I would buy it again. It is better than I was expecting. I do not have any complain about it.'\n",
            " 'Very good product, will purchase over and over again. A convenient way to purchase.']\n"
          ]
        }
      ],
      "source": [
        "idx = np.argsort(similarities.numpy())[::-1]\n",
        "\n",
        "for i in idx[:2]:\n",
        "    print(reviews[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EC8ZW3FijpDv",
        "outputId": "e78d0683-bc45-4db7-a01e-3d958b7bd315"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".\n",
            "\n",
            "Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "d = embedding.shape[1]\n",
        "index = faiss.IndexFlatL2(d)\n",
        "index.add(embedding)\n",
        "\n",
        "D, I = index.search(querry, 5)\n",
        "\n",
        "idx = np.argsort(I[0])[::-1]\n",
        "for i in idx[:2]:\n",
        "    print(reviews[i])\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRiXjt__fKxA",
        "outputId": "a5a79ac2-f3f6-408e-a5c2-fbb088dc3f22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".\n",
            "\n",
            "Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n = 50\n",
        "d = embedding.shape[1]\n",
        "quantize = faiss.IndexFlatL2(d)\n",
        "index = faiss.IndexIVFFlat(quantize, d, n)\n",
        "\n",
        "index.train(embedding)\n",
        "index.add(embedding)\n",
        "\n",
        "index.nprobe = 10\n",
        "D, I = index.search(querry, 5)\n",
        "\n",
        "idx = np.argsort(I[0])[::-1]\n",
        "for i in idx[:2]:\n",
        "    print(reviews[i])\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDaMzxACpaDp"
      },
      "source": [
        "### ChromaDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGNZsssnpU99"
      },
      "outputs": [],
      "source": [
        "import chromadb\n",
        "\n",
        "chroma_client = chromadb.Client()\n",
        "# collection = chroma_client.create_collection(name = \"reviews\")\n",
        "collection = chroma_client.create_collection(\n",
        "    name = \"reviews\",\n",
        "    metadata = {\"hnsw:space\": \"cosine\"}  # <--- sets the search method \"cosine\" \"l2\" \"ip\"\n",
        ")\n",
        "\n",
        "collection.add(\n",
        "    documents = sentences,\n",
        "    embeddings = sentence_embeddings.tolist(),\n",
        "    ids=[f\"id{i}\" for i in range(len(sentences))]\n",
        ")\n",
        "\n",
        "query = \"I love this device, it has a greate battery, nice design, and powerful cpu.\"\n",
        "query_emb = model.encode([query]).tolist()\n",
        "\n",
        "results = collection.query(query_embeddings = query_emb, n_results = 2)\n",
        "print(results[\"documents\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtELU2hlj58z"
      },
      "source": [
        "## Classification project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGnPLGcsiOzI"
      },
      "outputs": [],
      "source": [
        "# convert to only two lables\n",
        "label = (df[\"Score\"].values > 3).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hENYZhjwiOwq"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(embedding[:10000], label[:10000], test_size = 0.2, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqlrEDZkiOmR",
        "outputId": "1f17f522-a47e-4791-ce90-c4e3dc8fd75b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.20      0.33       492\n",
            "           1       0.79      0.99      0.88      1508\n",
            "\n",
            "    accuracy                           0.80      2000\n",
            "   macro avg       0.84      0.60      0.60      2000\n",
            "weighted avg       0.82      0.80      0.74      2000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## FAISS in LangChain\n",
        "\n",
        "```python\n",
        "# Similarity search with score\n",
        "docs_scores = vector_store.similarity_search_with_score(\"query\", k=5)\n",
        "\n",
        "# Max marginal relevance (diversity)\n",
        "docs = vector_store.max_marginal_relevance_search(\"query\", k=5)\n",
        "\n",
        "# Similarity search by vector\n",
        "docs = vector_store.similarity_search_by_vector(query_embedding, k=5)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMu6aZMsm5sn"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "# from langchain_community.docstore.in_memory import InMemoryDocstore\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name = \"all-MiniLM-L6-v2\")\n",
        "# index = faiss.IndexFlatL2(len(embeddings.embed_query(\"hello world\")))\n",
        "\n",
        "# vector_store = FAISS(\n",
        "#     embedding_function=embeddings,\n",
        "#     index=index,\n",
        "#     docstore=InMemoryDocstore(),\n",
        "#     index_to_docstore_id={},\n",
        "# )\n",
        "\n",
        "# when we use `from_texts` method, it creates a FAISS `index` under the hood\n",
        "# Automatically handles text-embedding mapping\n",
        "vector_store = FAISS.from_texts(\n",
        "    texts = reviews,\n",
        "    embedding = embeddings,\n",
        "    # metadatas=[{\"source\": f\"doc_{i}\"} for i in range(len(reviews))]  # Optional metadata\n",
        ")\n",
        "\n",
        "# Search returns documents with content and metadata\n",
        "docs = vector_store.similarity_search(\"your query\", k = 5)\n",
        "for doc in docs:\n",
        "    print(doc.page_content)\n",
        "    # print(doc.metadata)  # If you added metadata"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
