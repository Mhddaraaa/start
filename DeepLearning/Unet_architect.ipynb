{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80309191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nlb\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77ec9c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cufa' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "278f7550",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    def __init__(self, img_channel, classnum):\n",
    "        super().__init__()\n",
    "        self.img_channel = img_channel\n",
    "        self.classnum = classnum\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.downSample1 = self._convBlock(64, firstDown=True)\n",
    "        self.downSample2 = self._convBlock(128)\n",
    "        self.downSample3 = self._convBlock(256)\n",
    "        self.downSample4 = self._convBlock(512)\n",
    "        self.upsammple1 = self._convBlockTranspos(1024,firstUp=True)\n",
    "        self.upsammple2 = self._convBlockTranspos(512)\n",
    "        self.upsammple3 = self._convBlockTranspos(256)\n",
    "        self.upsammple4 = self._convBlockTranspos(128)\n",
    "        self.lastBlock = nn.Sequential(\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, self.classnum, kernel_size=1, padding='same')\n",
    "        )\n",
    "        \n",
    "    def forward(self, x:torch.tensor):\n",
    "        out1 = self.downSample1(x)\n",
    "        out = self.pool(out1)\n",
    "        out2 = self.downSample2(out)\n",
    "        out = self.pool(out2)\n",
    "        out3 = self.downSample3(out)\n",
    "        out = self.pool(out3)\n",
    "        out4 = self.downSample4(out)\n",
    "        out = self.pool(out4)\n",
    "\n",
    "        out = self.upsammple1(out)\n",
    "        out = torch.concat([out, out4], dim=1)\n",
    "        out = self.upsammple2(out)\n",
    "        out = torch.concat([out, out3], dim=1)\n",
    "        out = self.upsammple3(out)\n",
    "        out = torch.concat([out, out2], dim=1)\n",
    "        out = self.upsammple4(out)\n",
    "        out = torch.concat([out, out1], dim=1)\n",
    "        out = self.lastBlock(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def _convBlock(self, in_channel, firstDown=False):\n",
    "        if firstDown:\n",
    "            block = nn.Sequential(\n",
    "                nn.Conv2d(self.img_channel, in_channel, kernel_size=3, padding='same'),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout2d(0.2),\n",
    "                nn.Conv2d(in_channel, in_channel, kernel_size=3, padding='same'),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        else:\n",
    "            block = nn.Sequential(\n",
    "            nn.Conv2d(in_channel//2, in_channel, kernel_size=3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.Conv2d(in_channel, in_channel, kernel_size=3, padding='same'),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        return block\n",
    "    \n",
    "    def _convBlockTranspos(self, in_channel, firstUp=False):\n",
    "        if firstUp:\n",
    "            block = nn.Sequential(\n",
    "                nn.Conv2d(in_channel//2, in_channel, kernel_size=3, padding='same'),\n",
    "                nn.BatchNorm2d(in_channel),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout2d(0.2),\n",
    "                nn.Conv2d(in_channel, in_channel, kernel_size=3, padding='same'),\n",
    "                nn.BatchNorm2d(in_channel),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.ConvTranspose2d(in_channel, in_channel//2, kernel_size=2, stride=2),\n",
    "            )\n",
    "        else:\n",
    "            block = nn.Sequential(\n",
    "                nn.Conv2d(in_channel*2, in_channel, kernel_size=3, padding='same'),\n",
    "                nn.BatchNorm2d(in_channel),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout2d(0.2),\n",
    "                nn.Conv2d(in_channel, in_channel, kernel_size=3, padding='same'),\n",
    "                nn.BatchNorm2d(in_channel),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.ConvTranspose2d(in_channel, in_channel//2, kernel_size=2, stride=2),\n",
    "            )\n",
    "\n",
    "        return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca01a6dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0617, -0.0757, -0.0528,  ..., -0.0860, -0.0541, -0.0735],\n",
       "          [-0.0495, -0.0856, -0.0670,  ..., -0.0738, -0.0806, -0.0647],\n",
       "          [-0.0672, -0.0759, -0.0627,  ..., -0.0750, -0.0882, -0.0790],\n",
       "          ...,\n",
       "          [-0.0637, -0.0973, -0.0790,  ..., -0.0943, -0.0674, -0.0699],\n",
       "          [-0.0596, -0.0802, -0.0707,  ..., -0.0776, -0.0656, -0.0657],\n",
       "          [-0.0578, -0.0540, -0.0703,  ..., -0.0686, -0.0626, -0.0585]],\n",
       "\n",
       "         [[-0.0628, -0.0735, -0.0776,  ..., -0.0707, -0.0626, -0.0617],\n",
       "          [-0.0613, -0.0749, -0.0649,  ..., -0.0725, -0.0562, -0.0772],\n",
       "          [-0.0606, -0.0558, -0.0809,  ..., -0.0566, -0.0543, -0.0631],\n",
       "          ...,\n",
       "          [-0.0674, -0.0619, -0.0868,  ..., -0.0747, -0.0471, -0.0549],\n",
       "          [-0.0722, -0.0688, -0.0691,  ..., -0.0881, -0.0855, -0.0565],\n",
       "          [-0.0491, -0.0717, -0.0690,  ..., -0.0572, -0.0740, -0.0614]]]],\n",
       "       grad_fn=<ConvolutionBackward1>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((1, 3, 240, 240))\n",
    "model = Unet(3, 2)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cc673f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
